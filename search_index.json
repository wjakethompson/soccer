[
["index.html", "Soccer Predictions Using Bayesian Mixed Effects Models Preface", " Soccer Predictions Using Bayesian Mixed Effects Models Jake Thompson 2017-02-27 Preface This document was created in partial fulfillment of the requirements for the comprehensive examination for the Educational Psychology and Research doctoral program at the University of Kansas. The task assigned was to create a rating system for European soccer teams, and to use these ratings to predict the winners of the major domestic leagues (the German Budesliga, the Spanish La Liga, the French Ligue 1, the English Premier League, and the Italian Serie A), and the winner of the Union of European Football Associations (UEFA) Champion’s League. Each section of this document describes a specific step in the process of creating these predictions, from gathering the necessary data to creating output graphics. This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 3.0 United States License. "],
["intro.html", "1 Introduction 1.1 European soccer format 1.2 Document organization 1.3 Colophon", " 1 Introduction 1.1 European soccer format 1.1.1 Domestic leagues 1.1.2 UEFA Champions League 1.1.3 Domestic cups 1.2 Document organization 1.3 Colophon The source code for this document can be found at https://github.com/wjakethompson/soccer. The document was written with bookdown (Xie, 2016a), which simplifies the process of turning multiple R markdown files into a single output file (e.g., HTML, PDF, EPUB). This document was built with: devtools::session_info(c(&quot;bookdown&quot;, &quot;knitr&quot;, &quot;rmarkdown&quot;, &quot;rvest&quot;, &quot;purrr&quot;, &quot;dplyr&quot;, &quot;lubridate&quot;, &quot;rstan&quot;, &quot;ggplot2&quot;, &quot;DT&quot;)) #&gt; Session info -------------------------------------------------------------- #&gt; setting value #&gt; version R version 3.3.2 (2016-10-31) #&gt; system x86_64, linux-gnu #&gt; ui X11 #&gt; language (EN) #&gt; collate en_US.UTF-8 #&gt; tz &lt;NA&gt; #&gt; date 2017-02-27 #&gt; Packages ------------------------------------------------------------------ #&gt; package * version date source #&gt; assertthat 0.1 2013-12-06 cran (@0.1) #&gt; backports 1.0.5 2017-01-18 cran (@1.0.5) #&gt; base64enc 0.1-3 2015-07-28 cran (@0.1-3) #&gt; BH 1.62.0-1 2016-11-19 cran (@1.62.0-) #&gt; bitops 1.0-6 2013-08-17 cran (@1.0-6) #&gt; bookdown 0.3.9 2017-02-22 Github (rstudio/bookdown@a5ad84c) #&gt; caTools 1.17.1 2014-09-10 cran (@1.17.1) #&gt; colorspace 1.3-2 2016-12-14 cran (@1.3-2) #&gt; curl 2.3 2016-11-24 CRAN (R 3.3.2) #&gt; DBI 0.5-1 2016-09-10 cran (@0.5-1) #&gt; dichromat 2.0-0 2013-01-24 cran (@2.0-0) #&gt; digest 0.6.12 2017-01-27 CRAN (R 3.3.2) #&gt; dplyr 0.5.0 2016-06-24 cran (@0.5.0) #&gt; DT 0.2 2016-08-09 cran (@0.2) #&gt; evaluate 0.10 2016-10-11 cran (@0.10) #&gt; ggplot2 2.2.1 2016-12-30 cran (@2.2.1) #&gt; gridExtra 2.2.1 2016-02-29 cran (@2.2.1) #&gt; gtable 0.2.0 2016-02-26 cran (@0.2.0) #&gt; highr 0.6 2016-05-09 cran (@0.6) #&gt; htmltools 0.3.5 2016-03-21 cran (@0.3.5) #&gt; htmlwidgets 0.8 2016-11-09 cran (@0.8) #&gt; httr 1.2.1 2016-07-03 CRAN (R 3.3.2) #&gt; inline 0.3.14 2015-04-13 cran (@0.3.14) #&gt; jsonlite 1.2 2016-12-31 CRAN (R 3.3.2) #&gt; knitr 1.15.1 2016-11-22 cran (@1.15.1) #&gt; labeling 0.3 2014-08-23 cran (@0.3) #&gt; lattice 0.20-34 2016-09-06 CRAN (R 3.3.2) #&gt; lazyeval 0.2.0 2016-06-12 cran (@0.2.0) #&gt; lubridate 1.6.0 2016-09-13 cran (@1.6.0) #&gt; magrittr 1.5 2014-11-22 cran (@1.5) #&gt; markdown 0.7.7 2015-04-22 cran (@0.7.7) #&gt; MASS 7.3-45 2016-04-21 CRAN (R 3.3.2) #&gt; Matrix 1.2-7.1 2016-09-01 CRAN (R 3.3.2) #&gt; mime 0.5 2016-07-07 CRAN (R 3.3.2) #&gt; munsell 0.4.3 2016-02-13 cran (@0.4.3) #&gt; openssl 0.9.6 2016-12-31 CRAN (R 3.3.2) #&gt; plyr 1.8.4 2016-06-08 cran (@1.8.4) #&gt; purrr 0.2.2 2016-06-18 cran (@0.2.2) #&gt; R6 2.2.0 2016-10-05 CRAN (R 3.3.2) #&gt; RColorBrewer 1.1-2 2014-12-07 cran (@1.1-2) #&gt; Rcpp 0.12.9.3 2017-02-22 Github (RcppCore/Rcpp@8bf15c0) #&gt; RcppEigen 0.3.2.9.0 2016-08-21 cran (@0.3.2.9) #&gt; reshape2 1.4.2 2016-10-22 cran (@1.4.2) #&gt; rmarkdown 1.3 2016-12-21 cran (@1.3) #&gt; rprojroot 1.2 2017-01-16 cran (@1.2) #&gt; rstan 2.14.1 2016-12-28 cran (@2.14.1) #&gt; rvest 0.3.2 2016-06-17 cran (@0.3.2) #&gt; scales 0.4.1 2016-11-09 cran (@0.4.1) #&gt; selectr 0.3-1 2016-12-19 cran (@0.3-1) #&gt; StanHeaders 2.14.0-1 2017-01-09 cran (@2.14.0-) #&gt; stringi 1.1.2 2016-10-01 cran (@1.1.2) #&gt; stringr 1.2.0 2017-02-18 cran (@1.2.0) #&gt; tibble 1.2 2016-08-26 cran (@1.2) #&gt; xml2 1.1.1 2017-01-24 cran (@1.1.1) #&gt; yaml 2.1.14 2016-11-12 cran (@2.1.14) References "],
["define-model.html", "2 Defining the Model 2.1 The bivariate Poisson model 2.2 The game random intercept model", " 2 Defining the Model In soccer, the goals scored by a single team can be thought of as coming from a Poisson distribution. Thus, we can state that the two scores from a given game, \\(X\\) and \\(Y\\), are Poisson distributed. \\[\\begin{equation} \\begin{split} X &amp; \\sim Poisson(\\lambda_1)\\\\ Y &amp; \\sim Poisson(\\lambda_2) \\end{split} \\tag{2.1} \\end{equation}\\] This parameterization, however, assumes that the scores \\(X\\) and \\(Y\\) are independent of each other. In this project, the aim is to model the association between the two Poisson distributed variables. There are two methods for modeling this association that will be examined. The first is a bivariate Poisson distribution. The second is a mixed effects model with a random slope for each game. 2.1 The bivariate Poisson model In the bivariate Poisson, the scores for teams \\(A\\) and \\(B\\), \\(X_A\\) and \\(X_B\\), are random variables where \\(G_i \\sim Poisson(\\lambda_i),\\ i = 0,\\ 1,\\ 2\\). \\[\\begin{equation} \\begin{split} X_A &amp; = G_1 + G_0\\\\ X_B &amp; = G_2 + G_0 \\end{split} \\tag{2.2} \\end{equation}\\] And \\(X_A\\) and \\(X_B\\) are jointly distributed \\[\\begin{equation} (X_A,\\ X_B) \\sim BP(\\lambda_1,\\ \\lambda_2,\\ \\lambda_0) \\tag{2.3} \\end{equation}\\] In this parameterization, \\(X_A\\) and \\(X_B\\) are Poisson distributed with means equal to \\(\\lambda_1 + \\lambda_3\\) and \\(\\lambda_2 + \\lambda_3\\) respectively, with \\(\\lambda_3\\) representing the covariance between \\(X_A\\) and \\(X_B\\) (AlMuhayfith, Alzaid, &amp; Omair, 2016; Griffiths &amp; Milne, 1978; Kawamura, 1973). We can model these parameters just as we would model, for example, means in a normal distribution. Thus, for a given game, \\(i\\), \\[\\begin{equation} \\begin{split} (X_{Ai},\\ X_{Bi}) &amp; \\sim BP(\\lambda_{1i},\\ \\lambda_{2i},\\ \\lambda_{0i}),\\\\ log(\\lambda_{1i}) &amp; = \\omega_{1i}\\beta_{1},\\\\ log(\\lambda_{2i}) &amp; = \\omega_{2i}\\beta_{2},\\\\ log(\\lambda_{0i}) &amp; = \\omega_{0i}\\beta_{0} \\end{split} \\tag{2.4} \\end{equation}\\] where \\(\\omega\\) represents a matrix of independent variable, and \\(\\beta\\) denotes the regression coefficients (Karlis &amp; Ntzoufras, 2003, 2005). When predicting soccer games, the independent variables are the teams that are playing, and the regression coefficients represent the offensive or defensive strength of the teams (Groll, Kneib, Mayr, &amp; Schauberger, 2016). Specifically, we can model the two scores, \\(X\\), for teams \\(A\\) and \\(B\\), from a given game, \\(i\\), as \\[\\begin{align} log(X_{Ai}) &amp;= \\lambda_{1i} + \\lambda_{0i}, \\notag \\\\ log(X_{Bi}) &amp;= \\lambda_{2i} + \\lambda_{0i}, \\notag \\\\ \\lambda_{1i} &amp;= \\mu + \\eta H_i + \\alpha_A + \\delta_B, \\tag{2.5} \\\\ \\lambda_{2i} &amp;= \\mu + \\alpha_B + \\delta_A, \\tag{2.6} \\\\ \\lambda_{0i} &amp;= \\rho_A + \\rho_B \\tag{2.7} \\end{align}\\] Here, \\(\\mu\\) denotes the overall intercept, or the expected log goals for a team not playing at home, and \\(\\eta\\) represents the increase in expected log goals for a team playing at home. \\(H_i\\) is a dummary variable indicating whether game \\(i\\) was played at the home team’s stadium (1) or a neutral site (0). The estimates of team ability come from \\(\\alpha\\) and \\(\\delta\\), which represent the attacking and defensive abilities of the given team respectively. These can be modeled as fixed effects, or as random effects. Finally, \\(\\rho\\) denotes the change in expected covariance for each team (Whitaker, 2011). 2.1.1 Implementing the bivariate Poisson model The bivariate Poisson model can be fit using the following Stan code and the rstan package (Guo, Gabry, &amp; Goodrich, 2016). In the model code, I have modeled \\(\\alpha\\), \\(\\delta\\), and \\(\\rho\\) as random effects so that \\(\\mu\\) represents the overall mean. This means that positive \\(\\alpha\\) values and negative \\(\\delta\\) are good, as team wants the attack to add goals above the average, and the defense to result in the opponent have below average goals. I have also reparameterized the random effects so that Stan can sample from a \\(\\mathcal{N}(0,\\ 1)\\), which reduces computation time and increases the efficiency of the sampler to avoid divergent transitions (Stan Development Team, 2016b). data { int&lt;lower=1&gt; num_clubs; // number of clubs int&lt;lower=1&gt; num_games; // number of games int&lt;lower=1,upper=num_clubs&gt; home[num_games]; // home club for game g int&lt;lower=1,upper=num_clubs&gt; away[num_games]; // away club for game g int&lt;lower=0&gt; h_goals[num_games]; // home goals for game g int&lt;lower=0&gt; a_goals[num_games]; // away goals for game g int&lt;lower=0,upper=1&gt; homeg[num_games]; // home field for game g } parameters { vector[num_clubs] raw_alpha; // attacking intercepts vector[num_clubs] raw_delta; // defending intercepts vector[num_clubs] raw_rho; // covariance intercepts real mu; // fixed intercept real eta; // homefield real&lt;lower=0&gt; sigma_a; // attacking sd real&lt;lower=0&gt; sigma_d; // defending sd real&lt;lower=0&gt; sigma_r; // covariance sd } transformed parameters { vector[num_clubs] alpha; vector[num_clubs] delta; vector[num_clubs] rho; alpha = raw_alpha * sigma_a; delta = raw_delta * sigma_d; rho = raw_rho * sigma_r; } model { vector[num_games] lambda1; vector[num_games] lambda2; vector[num_games] lambda3; // priors raw_alpha ~ normal(0, 1); raw_delta ~ normal(0, 1); raw_rho ~ normal(0, 1); mu ~ normal(0, 10); eta ~ normal(0, 10); sigma_a ~ normal(0, 10); sigma_d ~ normal(0, 10); sigma_r ~ normal(0, 10); // likelihood for (g in 1:num_games) { lambda1[g] = exp(mu + (eta * homeg[g]) + alpha[home[g]] + delta[away[g]]); lambda2[g] = exp(mu + alpha[away[g]] + delta[home[g]]); lambda3[g] = exp(rho[home[g]] + rho[away[g]]); } h_goals ~ poisson(lambda1 + lambda3); a_goals ~ poisson(lambda2 + lambda3); } 2.2 The game random intercept model As an alternative to the bivariate Poisson model, one could model a random intercept for each game, rather than estimating \\(\\rho\\). Thus, the game random intercept model would be defined as \\[\\begin{align} log(X_{Ai}) &amp;= \\lambda_{1i}, \\notag \\\\ log(X_{Bi}) &amp;= \\lambda_{2i}, \\notag \\\\ \\lambda_{1i} &amp;= \\mu + \\eta H_i + \\alpha_A + \\delta_B + \\gamma_i, \\tag{2.8} \\\\ \\lambda_{2i} &amp;= \\mu + \\alpha_B + \\delta_A + \\gamma_i \\tag{2.9} \\end{align}\\] This model is very similar to the bivariate Poisson. The two rate parameters, \\(\\lambda_{1i}\\) and \\(\\lambda_{2i}\\), are defined the same, with only the addition of \\(\\gamma_i\\) denoting the random intercept for the game. This \\(\\gamma_i\\) replaces \\(\\lambda_{0i}\\) in the bivariate Poisson model. This has a couple of downstream effects on the estimation. First, in the bivariate Poisson model, \\(\\rho\\) is estimated for each team. Thus the convariance, \\(\\lambda_{0i}\\) is predicted for each game by the competing teams’ \\(\\rho\\) values. This also allows predictions to be made for future games about what the covariance or dependency between the teams will be. In contrast, game random intercept model doesn’t estimate predictors for this dependency. In this model, the dependency is treated as a random variable, with some variance to be estimated. Thus, although both models take into account the dependency between the two scores in a given game, the models make different assumptions about the nature of this dependency. 2.2.1 Implementing the game random intercept model The game random intercept model can be estimated using the following Stan code and the rstan package (Guo et al., 2016). As with the bivariate Poisson model, I have modeled \\(\\alpha\\) and \\(\\delta\\) as random effects so that \\(\\mu\\) represents the overall mean. The random effects are also reparameterized in the same way as they were in the bivariate Poisson to reduce computation time and increase efficiency (Stan Development Team, 2016b). data { int&lt;lower=1&gt; num_clubs; // number of clubs int&lt;lower=1&gt; num_games; // number of games int&lt;lower=1,upper=num_clubs&gt; home[num_games]; // home club for game g int&lt;lower=1,upper=num_clubs&gt; away[num_games]; // away club for game g int&lt;lower=0&gt; h_goals[num_games]; // home goals for game g int&lt;lower=0&gt; a_goals[num_games]; // away goals for game g int&lt;lower=0,upper=1&gt; homeg[num_games]; // home field for game g } parameters { vector[num_clubs] raw_alpha; // attacking intercepts vector[num_clubs] raw_delta; // defending intercepts vector[num_games] raw_gamma; // game intercepts real mu; // fixed intercept real eta; // homefield real&lt;lower=0&gt; sigma_a; // attacking sd real&lt;lower=0&gt; sigma_d; // defending sd real&lt;lower=0&gt; sigma_g; // game sd } transformed parameters { vector[num_clubs] alpha; vector[num_clubs] delta; vector[num_games] gamma; alpha = sigma_a * raw_alpha; delta = sigma_d * raw_delta; gamma = sigma_g * raw_gamma; } model { vector[num_games] lambda1; vector[num_games] lambda2; // priors raw_alpha ~ normal(0, 1); // attacking random effects raw_delta ~ normal(0, 1); // defending random effects raw_gamma ~ normal(0, 1); // game random effects mu ~ normal(0, 10); eta ~ normal(0, 10); sigma_a ~ normal(0, 10); sigma_d ~ normal(0, 10); sigma_g ~ normal(0, 10); // likelihood for (g in 1:num_games) { lambda1[g] = exp(mu + (eta * homeg[g]) + alpha[home[g]] + delta[away[g]] + gamma[g]); lambda2[g] = exp(mu + alpha[away[g]] + delta[home[g]] + gamma[g]); } h_goals ~ poisson(lambda1); a_goals ~ poisson(lambda2); } References "],
["simulation.html", "3 Simulation Study 3.1 Data generation 3.2 Model estimation 3.3 Running the simulation 3.4 Simulation results", " 3 Simulation Study In order to evaluate these two models, I conducted a small scale simulation study. I generated 100 data sets from each of the bivariate Poisson and game random intercept models (for 200 data sets total). For each data set, both of the models were estimated to determine how well they were able to recover the attacking and defensive parameters for each team when the data generating model did and did not match the model. 3.1 Data generation Data was simulated to mimic the major domestic European leagues. For each data set, 20 clubs were generated, with each club playing all other clubs twice, once at home, and once away, for a total of 380 games. For both data generating models, \\(\\alpha\\) and \\(\\delta\\) parameters were drawn from a \\(\\mathcal{N}(0,0.35)\\). Both \\(\\rho\\) in the bivariate Poisson and \\(\\gamma\\) in the game random intercept model were sampled from a \\(\\mathcal{N}(0,0.1)\\) distribution. For all models, \\(\\mu\\) was set to 0, and \\(\\eta\\) was set to 0.5. These distributions were based on preliminary analyses using the 2015-16 English Premier League data. For each game, \\(\\lambda\\) values were calculated based on the parameters that were generated for each team (and game for the game random intercept model). Scores were then randomly generated using the rpois() function. Full data generation functions can be see in Appendix A.1 and A.2. When simulating the data sets, the portableParallelSeeds package was used to ensure that the data generation was completely replicable, and that the random number streams were not overlapping (???). 3.2 Model estimation In total, 200 data sets were generated: 100 from the bivariate Poisson, and 100 from the game random intercept model. For each data set, both the bivariate Poisson and game random intercept model were estimated. Thus, each model was estimated 100 times on a data set from the matching data generation method, and 100 times on mis-matched data. For each estimation, 2 chains were run with 15000 iterations. The first 5000 iterations of each chain were discarded for burnin. This resulted in a total of 20000 retained iterations that made up the final posterior distributions. The thinning interval was set to 1 (no thinning). Finally, the target proposal acceptance rate during the adaptation period was set to 0.99. This forces the algorithm to take smaller steps, which decreases efficiency. However, this also helps to eliminate divergent transitions, which are common when parameter estimates are close to their bounds, such as a variance very close to 0 (Stan Development Team, 2016b, 2016a). The full model estimation function can be seen in Appendix A.3. 3.3 Running the simulation The following code was used to run the simulation. I first define the total number of replications and the number of random streams needed for each replication. I then use portableParallelSeeds (???) to create seeds for each replication, and save them. Data sets are then generated from each model, with the number of data sets from each model being equal to half of the total number of replications specified by n_reps. Finally, I create one list that contains all of the data sets, simulation_data, and map the simulation function to each element of that list using the purrr package (Wickham, 2016a). # Define parameters for the simulation n_reps &lt;- 200 streams_per_rep &lt;- 1 # Create the seed warehouse project_seeds &lt;- seedCreator(n_reps, streams_per_rep, seed = 9416) save(project_seeds, file = &quot;_data/simulation_seeds.rda&quot;) # Create data sets bivpois_data &lt;- lapply(X = 1:(n_reps / 2), FUN = generate_bivpois, seeds = project_seeds, num_club = 20) gri_data &lt;- lapply(X = ((n_reps / 2) + 1):n_reps, FUN = generate_gri, seeds = project_seeds, num_club = 20) simulation_data &lt;- c( bivpois_data, gri_data ) simulation &lt;- map_df(.x = simulation_data, .f = simulation_fun) save(simulation, file = &quot;_data/simulation.rda&quot;) 3.4 Simulation results References "],
["gather-data.html", "4 Gather Data 4.1 Domestic league inclusion 4.2 Non-domestic competition inclusion 4.3 Domestic competition inclusion 4.4 Collect club websites 4.5 Scrape game data", " 4 Gather Data Perhaps the most important part of any data analysis is the collection of the data. If you don’t have the data necessary to support the model you want to estimate, or the conclusions you want to draw, no amount of tinkering with the model or results can save you. The data for this project was collected using web scraping via the rvest (Wickham, 2016b) and dplyr (Wickham &amp; Francois, 2016) packages. The scores for each game in a season for a given team can be found on ESPN’s website. For example, all of Barcelona’s games can be found here. Given that we have access to the results for any team available on ESPN, the question becomes which teams to include in the analysis. I chose teams that particpated in specific domestic leagues or in certain tournaments or competitions. The rationale for each selection is below. 4.1 Domestic league inclusion Because one goal of the project was to predict the 5 major European domestic leagues, all teams from the English Premier League, German Bundesliga, French Ligue 1, Spanish La Liga, and Italian Serie A were included. I also included the second tier leagues from these countries, if they were available. This included the English League Championship, German 2. Bundesliga, French Ligue 2, and Italian Serie B. The other major goal was to predict the UEFA Champion’s League (UCL). Many of the UCL teams come from the major domestic leagues, however many teams do not. Thus, I also included teams from the Belgian Jupiler League, Danish SAS-Ligaen, Dutch Eredivisie, Portuguese Liga, Russian Premier League, Scottish Premiership, Swiss Super League, and Turkish Super Lig. These leagues were selected because they all had teams reach the knockout stage of the UCL, and thus would have sufficient crossover with the major leagues. To get the URLs for each team, we can write a function that uses the rvest package to pull hyperlinks of of the league pages called scrape_league(). See Appendix B.1 for the full function. This function takes in a URL for a given league, and returns a data frame with the club names, the totals goals scored by and against each club in league play, the points each club has accumulated, and the club’s URL. For a full description of how the rvest package works, see this webinar (Grolemund, 2016). 4.2 Non-domestic competition inclusion Although many of the teams participating in the UCL come from the leagues the leagues outlines above, not all due. A few come from smaller leagues that are not covered by ESPN. Thus, all teams that participated in the group stage of the UCL were included. Additionally, teams that didn’t qualify for the UCL, and some teams that did qualify for the UCL, but didn’t make it out of the group stage, play in the second tier Eurpoa League tournament. Because this tournament includes more overlap between the leagues, all teams participating in the Europa league were also included. Finally, the International Champions Cup is a relatively new event that pairs top teams from Europe against each other around the world. All participants in this event were also included. The webpages for these competitions are formatted slightly differently than those for the domestic leagues, so we will need a slightly different function to scrape these team URLs, scrape_major_cup() (see Appendix B.2). Unlike the league scraper, this function only returns the club, and the URL for the club. 4.3 Domestic competition inclusion Finally, in addition to domestic leagues and international club competitions, European teams also compete in domestic tournaments. These competitions were also included to increase the number of data points for the top teams, as well as to increase the overlap between the first and second tier leagues of the top countries. All participants were included from Spain’s Copa del Ray and Spanish Super Cup, Italy’s Coppa Italia, France’s Coupe de France and Coupe de la Ligue, Germany’s DFB Pokal, and England’s FA Cup and League Cup. These webpages are also formatted differently, so we have one final function to get the team URLs, scrape_dom_cup() (see Appendix B.3). As with the scraper for the international competitions, this scraper also returns the club name and club URL. 4.4 Collect club websites Now that we have defined the functions, we can use the purrr package (Wickham, 2016a) to map the function to each league or competition URL. For more information on the purrr package see R for Data Science (Wickham &amp; Grolemund, 2016). First we create a list of URLs for each type of scraper. leagues &lt;- list( belgium = &quot;http://www.espnfc.us/belgian-jupiler-league/6/table&quot;, denmark = &quot;http://www.espnfc.us/danish-sas-ligaen/7/table&quot;, england = &quot;http://www.espnfc.us/english-premier-league/23/table&quot;, england2 = &quot;http://www.espnfc.us/english-league-championship/24/table&quot;, france = &quot;http://www.espnfc.us/french-ligue-1/9/table&quot;, france2 = &quot;http://www.espnfc.us/french-ligue-2/96/table&quot;, germany = &quot;http://www.espnfc.us/german-bundesliga/10/table&quot;, germany2 = &quot;http://www.espnfc.us/german-2-bundesliga/97/table&quot;, italy = &quot;http://www.espnfc.us/italian-serie-a/12/table&quot;, italy2 = &quot;http://www.espnfc.us/italian-serie-b/99/table&quot;, netherlands = &quot;http://www.espnfc.us/dutch-eredivisie/11/table&quot;, portugal = &quot;http://www.espnfc.us/portuguese-liga/14/table&quot;, russia = &quot;http://www.espnfc.us/russian-premier-league/106/table&quot;, scotland = &quot;http://www.espnfc.us/scottish-premiership/45/table&quot;, spain = &quot;http://www.espnfc.us/spanish-primera-division/15/table&quot;, switzerland = &quot;http://www.espnfc.us/swiss-super-league/17/table&quot;, turkey = &quot;http://www.espnfc.us/turkish-super-lig/18/table&quot; ) major_cups &lt;- list( champions_league = &quot;http://www.espnfc.us/uefa-champions-league/2/table&quot;, europa_league = &quot;http://www.espnfc.us/uefa-europa-league/2310/table&quot;, icc = &quot;http://www.espnfc.us/international-champions-cup/2326/table&quot; ) domestic_cups &lt;- list( copa_del_rey = &quot;http://www.espnfc.us/spanish-copa-del-rey/80/statistics/fairplay&quot;, coppa_italia = &quot;http://www.espnfc.us/italian-coppa-italia/2192/statistics/fairplay&quot;, coupe_de_france = &quot;http://www.espnfc.us/french-coupe-de-france/182/statistics/fairplay&quot;, coupe_de_la_ligue = &quot;http://www.espnfc.us/french-coupe-de-la-ligue/159/statistics/fairplay&quot;, dfb_pokal = &quot;http://www.espnfc.us/german-dfb-pokal/2061/statistics/fairplay&quot;, efl_cup = &quot;http://www.espnfc.us/efl-cup/41/statistics/fairplay&quot;, fa_cup = &quot;http://www.espnfc.us/english-fa-cup/40/statistics/fairplay&quot;, spanish_super_cup = &quot;http://www.espnfc.us/spanish-super-cup/431/statistics/fairplay&quot; ) We can then map our functions to the defined URLs. library(rvest) library(purrr) library(dplyr) league_urls &lt;- map_df(.x = leagues, .f = scrape_league) major_cup_urls &lt;- map_df(.x = major_cups, .f = scrape_major_cup) domestic_cup_urls &lt;- map_df(.x = domestic_cups, .f = scrape_dom_cup) league_urls #&gt; # A tibble: 304 × 5 #&gt; club goals_for goals_against points #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Club Brugge 53 20 58 #&gt; 2 Anderlecht 62 27 58 #&gt; 3 Zulte-Waregem 44 35 50 #&gt; 4 KV Oostende 50 35 48 #&gt; 5 Royal Charleroi SC 32 25 47 #&gt; 6 KV Mechelen 38 31 45 #&gt; # ... with 298 more rows, and 1 more variables: club_url &lt;chr&gt; major_cup_urls #&gt; # A tibble: 97 × 2 #&gt; club #&gt; &lt;chr&gt; #&gt; 1 Arsenal #&gt; 2 Paris Saint-Germain #&gt; 3 Ludogorets Razgrad #&gt; 4 FC Basel #&gt; 5 Napoli #&gt; 6 Benfica #&gt; # ... with 91 more rows, and 1 more variables: club_url &lt;chr&gt; domestic_cup_urls #&gt; # A tibble: 273 × 2 #&gt; club club_url #&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Barcelona http://www.espnfc.us/club/barcelona/83/index #&gt; 2 Alavés http://www.espnfc.us/club/alaves/96/index #&gt; 3 Atletico Madrid http://www.espnfc.us/club/atletico-madrid/1068/index #&gt; 4 Eibar http://www.espnfc.us/club/eibar/3752/index #&gt; 5 Celta Vigo http://www.espnfc.us/club/celta-vigo/85/index #&gt; 6 AD Alcorcon http://www.espnfc.us/club/ad-alcorcon/11121/index #&gt; # ... with 267 more rows The next step is to create a data frame of all the clubs and their URLs. Many teams participate in multiple competitions that were included, so we will only keep one instance. url_lookup &lt;- list( select(league_urls, club, club_url), major_cup_urls, domestic_cup_urls ) %&gt;% bind_rows() %&gt;% filter(!is.na(club_url)) %&gt;% unique() full_urls &lt;- league_urls %&gt;% select(-club_url) %&gt;% full_join(url_lookup, by = &quot;club&quot;) %&gt;% filter(!is.na(club_url)) full_urls #&gt; # A tibble: 418 × 5 #&gt; club goals_for goals_against points #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Club Brugge 53 20 58 #&gt; 2 Anderlecht 62 27 58 #&gt; 3 Zulte-Waregem 44 35 50 #&gt; 4 KV Oostende 50 35 48 #&gt; 5 Royal Charleroi SC 32 25 47 #&gt; 6 KV Mechelen 38 31 45 #&gt; # ... with 412 more rows, and 1 more variables: club_url &lt;chr&gt; 4.5 Scrape game data Now that we have all of the team URLs, we can scrape the game data from each team’s page on ESPN. To do this, we’ll define a new scraper function, scrape_team() (see Appendix B.4). Because there are so many teams to scrape, it’s possible we may overload ESPN’s server request limit. Therefore, we’ll define a safe version of the read_html() function that will allow us to check if the website was read correctly. Now we map this function to all of our club URLs, just like we did with the league URLs. Note that we also use the lubridate package (Grolemund, Spinu, &amp; Wickham, 2016) to format dates. library(lubridate) safe_read_html &lt;- safely(read_html) full_data &lt;- map2_df(.x = full_urls$club_url, .y = full_urls$club, .f = scrape_team) Finally, we just have to do a little cleaning. We will remove duplicate games, and replace the abbreviations that ESPN uses in their scores with the full club name. team_lookup &lt;- select(full_data, -team_data) full_data &lt;- bind_rows(full_data$team_data) %&gt;% unique() %&gt;% arrange(date, home) %&gt;% left_join(select(full_data, -team_data), by = c(&quot;home&quot; = &quot;abbrev&quot;)) %&gt;% rename(home_club = club) %&gt;% left_join(select(full_data, -team_data), by = c(&quot;away&quot; = &quot;abbrev&quot;)) %&gt;% rename(away_club = club) %&gt;% mutate( real_home = ifelse(is.na(home_club), home, home_club), real_away = ifelse(is.na(away_club), away, away_club), home = real_home, away = real_away ) %&gt;% select(-(home_club:real_away)) %&gt;% mutate(home_game = ifelse(competition %in% c(&quot;Champions Cup&quot;), 0, 1)) %&gt;% filter(!(date &lt; Sys.Date() &amp; is.na(home_goals))) %&gt;% filter(date &gt; ymd(&quot;2016-03-01&quot;)) %&gt;% rename(h_goals = home_goals, a_goals = away_goals) DT::datatable(full_data, options = list(pageLength = 5, scrollX = TRUE)) References "],
["fit-model.html", "5 Fitting the Model 5.1 Convergence", " 5 Fitting the Model 5.1 Convergence "],
["predict.html", "6 Making Predictions", " 6 Making Predictions "],
["simulation-functions.html", "A Simulation Functions A.1 Generate bivariate Poisson A.2 Generate game random intercept A.3 Fit models to simualted data", " A Simulation Functions A.1 Generate bivariate Poisson generate_bivpois &lt;- function(run, seeds, num_club) { setSeeds(seeds, run = run) teams &lt;- data_frame( club = paste0(&quot;club&quot;, sprintf(&quot;%02d&quot;, seq_len(num_club))), attack = rnorm(n = num_club, mean = 0, sd = 0.35), defend = rnorm(n = num_club, mean = 0, sd = 0.35), cov = rnorm(n = num_club, mean = 0, sd = 0.1) ) games &lt;- teams %&gt;% select(club) %&gt;% flatten_chr() %&gt;% crossing(., .) colnames(games) &lt;- c(&quot;home&quot;, &quot;away&quot;) games &lt;- games %&gt;% filter(home != away) %&gt;% left_join(teams, by = c(&quot;home&quot; = &quot;club&quot;)) %&gt;% rename(h_att = attack, h_def = defend, h_cov = cov) %&gt;% left_join(teams, by = c(&quot;away&quot; = &quot;club&quot;)) %&gt;% rename(a_att = attack, a_def = defend, a_cov = cov) %&gt;% mutate( lambda1 = exp(0 + 0.5 + h_att + a_def), lambda2 = exp(0 + a_att + h_def), lambda3 = exp(h_cov + a_cov), h_goals = rpois(n = nrow(.), lambda = (lambda1 + lambda3)), a_goals = rpois(n = nrow(.), lambda = (lambda2 + lambda3)), home_game = 1 ) %&gt;% select(home, away, h_goals, a_goals, home_game) list( method = &quot;bivpois&quot;, teams = teams, games = games ) } A.2 Generate game random intercept generate_gri &lt;- function(run, seeds, num_club) { setSeeds(seeds, run = run) teams &lt;- data_frame( club = paste0(&quot;club&quot;, sprintf(&quot;%02d&quot;, seq_len(num_club))), attack = rnorm(n = num_club, mean = 0, sd = 0.35), defend = rnorm(n = num_club, mean = 0, sd = 0.35) ) games &lt;- teams %&gt;% select(club) %&gt;% flatten_chr() %&gt;% crossing(., .) colnames(games) &lt;- c(&quot;home&quot;, &quot;away&quot;) games &lt;- games %&gt;% filter(home != away) %&gt;% left_join(teams, by = c(&quot;home&quot; = &quot;club&quot;)) %&gt;% rename(h_att = attack, h_def = defend) %&gt;% left_join(teams, by = c(&quot;away&quot; = &quot;club&quot;)) %&gt;% rename(a_att = attack, a_def = defend) %&gt;% mutate( gamma = rnorm(n = nrow(.), mean = 0, sd = 0.1), lambda1 = exp(0 + 0.5 + h_att + a_def + gamma), lambda2 = exp(0 + a_att + h_def + gamma), h_goals = rpois(n = nrow(.), lambda = (lambda1)), a_goals = rpois(n = nrow(.), lambda = (lambda2)), home_game = 1 ) %&gt;% select(home, away, h_goals, a_goals, home_game) list( method = &quot;gri&quot;, teams = teams, games = games ) } A.3 Fit models to simualted data simulation_fun &lt;- function(x) { team_codes &lt;- data_frame( club = sort(unique(c(x$games$home, x$games$away))) ) %&gt;% mutate(code = seq_len(nrow(.))) fit_data &lt;- left_join(x$games, team_codes, by = c(&quot;home&quot; = &quot;club&quot;)) %&gt;% rename(home_code = code) %&gt;% left_join(team_codes, by = c(&quot;away&quot; = &quot;club&quot;)) %&gt;% rename(away_code = code) stan_data &lt;- list( num_clubs = nrow(team_codes), num_games = nrow(fit_data), home = fit_data$home_code, away = fit_data$away_code, h_goals = fit_data$h_goals, a_goals = fit_data$a_goals, homeg = fit_data$home_game ) bivpois &lt;- stan(file = &quot;_data/stan-models/biv_pois.stan&quot;, data = stan_data, chains = 2, iter = 15000, warmup = 5000, init = &quot;random&quot;, thin = 1, cores = 2, control = list(adapt_delta = 0.99)) gri &lt;- stan(file = &quot;_data/stan-models/gri.stan&quot;, data = stan_data, chains = 2, iter = 15000, warmup = 5000, init = &quot;random&quot;, thin = 1, cores = 2, control = list(adapt_delta = 0.99)) bivpois_maxrhat &lt;- as.data.frame(summary(bivpois)[[1]]) %&gt;% select(Rhat) %&gt;% flatten_dbl() %&gt;% max() gri_maxrhat &lt;- as.data.frame(summary(gri)[[1]]) %&gt;% select(Rhat) %&gt;% flatten_dbl() %&gt;% max() bivpois_params &lt;- rstan::extract(bivpois, pars = c(&quot;mu&quot;, &quot;eta&quot;, &quot;alpha&quot;, &quot;delta&quot;, &quot;rho&quot;)) gri_params &lt;- rstan::extract(gri, pars = c(&quot;mu&quot;, &quot;eta&quot;, &quot;alpha&quot;, &quot;delta&quot;)) bivpois_alpha &lt;- colMeans(bivpois_params$alpha) bivpois_delta &lt;- colMeans(bivpois_params$delta) gri_alpha &lt;- colMeans(gri_params$alpha) gri_delta &lt;- colMeans(gri_params$delta) bivpois_alpha_bias &lt;- mean(bivpois_alpha - x$teams$attack) bivpois_delta_bias &lt;- mean(bivpois_delta - x$teams$defend) bivpois_alpha_mse &lt;- mean((bivpois_alpha - x$teams$attack)^2) bivpois_delta_mse &lt;- mean((bivpois_delta - x$teams$defend)^2) gri_alpha_bias &lt;- mean(gri_alpha - x$teams$attack) gri_delta_bias &lt;- mean(gri_delta - x$teams$defend) gri_alpha_mse &lt;- mean((gri_alpha - x$teams$attack)^2) gri_delta_mse &lt;- mean((gri_delta - x$teams$defend)^2) data_frame( generator = x$method, bivpois_rhat = bivpois_maxrhat, bivpois_params = list(list(bivpois_alpha = bivpois_alpha, bivpois_delta = bivpois_delta)), bivpois_alpha_bia = bivpois_alpha_bias, bivpois_delta_bias = bivpois_delta_bias, bivpois_alpha_mse = bivpois_alpha_mse, bivpois_delta_mse = bivpois_delta_mse, gri_rhat = gri_maxrhat, gri_params = list(list(gri_alpha = gri_alpha, gri_delta = gri_delta)), gri_alpha_bias, gri_delta_bias, gri_alpha_mse, gri_delta_mse ) } "],
["scrape-functions.html", "B Web Scraping Functions B.1 Scrape league pages B.2 Scrape international cups B.3 Scrape domestic cups B.4 Scrape games", " B Web Scraping Functions B.1 Scrape league pages scrape_league &lt;- function(x) { url_data &lt;- read_html(x) league_table &lt;- url_data %&gt;% html_nodes(css = &quot;table&quot;) %&gt;% html_table() league_table &lt;- league_table[[1]] colnames(league_table) &lt;- as.character(league_table[1,]) colnames(league_table) &lt;- make.names(colnames(league_table), unique = TRUE) league_table &lt;- league_table[-1,] league_table &lt;- league_table %&gt;% select(club = TEAM, goals_for = `F`, goals_against = A, points = PTS) %&gt;% mutate(club = trimws(club, which = &quot;both&quot;)) teams &lt;- url_data %&gt;% html_nodes(&quot;td a&quot;) %&gt;% html_text() %&gt;% as.character() %&gt;% trimws(which = &quot;both&quot;) team_urls &lt;- url_data %&gt;% html_nodes(&quot;td a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% as.character() league_table &lt;- league_table %&gt;% left_join(data_frame(club = teams, club_url = team_urls), by = &quot;club&quot;) %&gt;% as_data_frame() return(league_table) } B.2 Scrape international cups scrape_major_cup &lt;- function(x) { url_data &lt;- read_html(x) league_table &lt;- url_data %&gt;% html_nodes(css = &quot;table&quot;) %&gt;% html_table() league_table &lt;- map_df(.x = league_table, .f = function(x) { colnames(x) &lt;- as.character(x[1,]) colnames(x) &lt;- make.names(colnames(x), unique = TRUE) x &lt;- x[-1,] x &lt;- x %&gt;% select(club = TEAM) return(x) }) %&gt;% bind_rows() %&gt;% mutate(club = trimws(club, which = &quot;both&quot;)) teams &lt;- url_data %&gt;% html_nodes(&quot;td a&quot;) %&gt;% html_text() %&gt;% as.character() %&gt;% trimws(which = &quot;both&quot;) team_urls &lt;- url_data %&gt;% html_nodes(&quot;td a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% as.character() league_table &lt;- league_table %&gt;% left_join(data_frame(club = teams, club_url = team_urls), by = &quot;club&quot;) %&gt;% as_data_frame() return(league_table) } B.3 Scrape domestic cups scrape_dom_cup &lt;- function(x) { url_data &lt;- read_html(x) teams &lt;- url_data %&gt;% html_nodes(&quot;#stats-fair-play a&quot;) %&gt;% html_text() %&gt;% as.character() %&gt;% trimws(which = &quot;both&quot;) team_urls &lt;- url_data %&gt;% html_nodes(&quot;#stats-fair-play a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% as.character() data_frame( club = teams, club_url = team_urls ) } B.4 Scrape games scrape_team &lt;- function(x, y) { x &lt;- gsub(&quot;/index&quot;, &quot;/fixtures&quot;, x, fixed = TRUE) cont &lt;- TRUE while(cont) { url_data &lt;- safe_read_html(x) if(is.null(url_data[[1]])) { closeAllConnections() Sys.sleep(5) } else { url_data &lt;- url_data[[1]] cont &lt;- FALSE } } date &lt;- url_data %&gt;% html_nodes(&quot;.headline&quot;) %&gt;% html_text() %&gt;% as.character() if (&quot;LIVE&quot; %in% date) { date[which(date == &quot;LIVE&quot;)] &lt;- format(Sys.Date(), &quot;%b %d, %Y&quot;) } date &lt;- mdy(date) home_team &lt;- url_data %&gt;% html_nodes(&quot;.score-home-team .team-name&quot;) %&gt;% html_text() %&gt;% as.character() away_team &lt;- url_data %&gt;% html_nodes(&quot;.score-away-team .team-name&quot;) %&gt;% html_text() %&gt;% as.character() home_score &lt;- url_data %&gt;% html_nodes(&quot;.home-score&quot;) %&gt;% html_text() %&gt;% as.character() %&gt;% gsub(&quot; &quot;, &quot;&quot;, x = .) %&gt;% gsub( &quot; *\\\\(.*?\\\\) *&quot;, &quot;&quot;, x = .) %&gt;% as.numeric() away_score &lt;- url_data %&gt;% html_nodes(&quot;.away-score&quot;) %&gt;% html_text() %&gt;% as.character() %&gt;% gsub(&quot; &quot;, &quot;&quot;, x = .) %&gt;% gsub( &quot; *\\\\(.*?\\\\) *&quot;, &quot;&quot;, x = .) %&gt;% as.numeric() competition &lt;- url_data %&gt;% html_nodes(&quot;.score-column.score-competition&quot;) %&gt;% html_text() %&gt;% as.character() team_data &lt;- data_frame( date = date, home = home_team, away = away_team, home_goals = home_score, away_goals = away_score, competition = competition ) %&gt;% arrange(date) %&gt;% unique() abbrev &lt;- as_data_frame(table(c(team_data$home, team_data$away))) %&gt;% top_n(n = 1, wt = n) %&gt;% select(Var1) %&gt;% flatten_chr() if (nrow(team_data) &lt; 3) { ret_data &lt;- data_frame( club = y, abbrev = y, team_data = NA ) } else { if (abbrev == &quot;Sporting&quot;) { team_data$home[which(team_data$home == &quot;Sporting&quot;)] &lt;- y team_data$away[which(team_data$away == &quot;Sporting&quot;)] &lt;- y ret_data &lt;- data_frame( club = y, abbrev = y, team_data = list(team_data) ) } else { team_data &lt;- filter(team_data, home != &quot;Sporting&quot;, away != &quot;Sporting&quot;) ret_data &lt;- data_frame( club = y, abbrev = abbrev, team_data = list(team_data) ) } } return(ret_data) } "],
["references.html", "References", " References "]
]
