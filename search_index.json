[
["index.html", "Soccer Predictions Using Bayesian Mixed Effects Models Preface", " Soccer Predictions Using Bayesian Mixed Effects Models Jake Thompson 2017-03-06 Preface This document was created in partial fulfillment of the requirements for the comprehensive examination for the Educational Psychology and Research doctoral program at the University of Kansas. The task assigned was to create a rating system for European soccer teams, and to use these ratings to predict the winners of the major domestic leagues (the German Budesliga, the Spanish La Liga, the French Ligue 1, the English Premier League, and the Italian Serie A), and the winner of the Union of European Football Associations (UEFA) Champion’s League. Each section of this document describes a specific step in the process of creating these predictions, from gathering the necessary data to creating output graphics. This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 3.0 United States License. "],
["intro.html", "1 Introduction 1.1 European soccer format 1.2 Document organization 1.3 Colophon", " 1 Introduction The goal of this project is to predict winners of the major domestic European soccer leagues and the UEFA Champions League. Necessarily, this means that the real goal is to accurately predict the outcomes of individual games. To do this, I estimate team abilities using Bayesian mixed effects models. The estimated abilities can then be used to predict the outcomes of games that have yet to be played. Before diving into the process of developing and estimating these models, it will be useful to have a brief introduction to how competitions are structured for European soccer teams. An understanding of the various competitions will help clarify why teams are or are not included in the estimation of the model, and make more obvious how predictions should be made. 1.1 European soccer format Unlike most American sports leagues (e.g., NFL, NBA, MLB, etc.), European soccer teams compete in a variety of domestic and international competitions. In general, these competitions fall into one of three major categories: Domestic leagues Domestic cups FIFA/UEFA Competitions 1.1.1 Domestic leagues Domestic leagues are most analogous to the regular season of the major American sports. In most domestic European soccer leagues, the league follows a double round robin structure with each team playing every other team twice: once at home and once away. Teams are awarded 3 points for a victory, 1 point for a tie, and 0 points for a loss. Once all the games have been played, the team with the most points wins the league. 1.1.2 Domestic cups European leagues also host domestic cups. For the most part, domestic tournaments consist of all eligible professional teams from a country, not just the teams from the highest league (this would be analogous to a baseball tournament where minor league and major league teams all competed against each other). These cups can either be straight knockout style tournaments (e.g., March Madness for NCAA basketball), or each leg can have two legs where the teams involved play twice, once at each team’s home stadium. Because of the vast number of teams involved in these cups, entrance into the tournament is usually staggered so that the best teams are guaranteed places in the later rounds. 1.1.3 FIFA and UEFA Competitions These are the international tournaments. For this project, the focus is on the UEFA Champions League. This tournament consists of several qualifying rounds before the tournament proper (e.g., play-in games). Once the tournament proper begins, the final 32 teams are placed into 8 groups of 4 teams each. A team plays every team in its group twice, once at home and once away, with points awarded the same as for domestic leagues (see section 1.1.1). At the end of group play, the two teams with the most points from each group advance to the final 16. From this point on, the tournament follows the structure of a knockout tournament, with each round having two legs (one home and one away game). This continues until the final, which is only a single game played at a neutral location. 1.2 Document organization This document steps through the process that was followed to create the predictions for the major European domestic leagues and the UEFA Champions League. I start by defining two possible models for estimating club ability in Section 2. I then conduct a small scale simulation study in Section 3 to determine if one of the models is better able to recover estimates of team ability. Sections 4 and 5 focus on gather the data to be used and estimating the model respectively. In Section 6, the estimates from the model are used to predict the outcomes of the domestic leagues and the UEFA Champions League, and output graphics are created. Finally, Section 7 outlines the limitations of this approach and possible improvements to the model. 1.3 Colophon The source code for this document can be found at https://github.com/wjakethompson/soccer. The document was written with bookdown (Xie, 2016a), which simplifies the process of turning multiple R markdown files into a single output file (e.g., HTML, PDF, EPUB). This document was built with: load(&quot;_data/session_info.rda&quot;) devtools:::print.session_info(session_info) #&gt; Session info -------------------------------------------------------------- #&gt; setting value #&gt; version R version 3.3.2 (2016-10-31) #&gt; system x86_64, darwin13.4.0 #&gt; ui RStudio (1.0.136) #&gt; language (EN) #&gt; collate en_US.UTF-8 #&gt; tz America/Chicago #&gt; date 2017-02-27 #&gt; Packages ------------------------------------------------------------------ #&gt; package * version date #&gt; assertthat 0.1 2013-12-06 #&gt; backports 1.0.4 2016-10-24 #&gt; base64enc 0.1-3 2015-07-28 #&gt; BH 1.62.0-1 2016-11-19 #&gt; bitops 1.0-6 2013-08-17 #&gt; bookdown 0.3.7 2017-01-15 #&gt; car 2.1-3 2016-08-11 #&gt; caTools 1.17.1 2014-09-10 #&gt; colorspace 1.2-6 2015-03-11 #&gt; curl 2.1 2016-09-22 #&gt; DBI 0.5-1 2016-09-10 #&gt; dichromat 2.0-0 2013-01-24 #&gt; digest 0.6.11 2017-01-03 #&gt; dplyr * 0.5.0 2016-06-24 #&gt; DT 0.2 2016-08-09 #&gt; evaluate 0.10 2016-10-11 #&gt; ggplot2 * 2.2.1.9000 2017-01-26 #&gt; gridExtra 2.2.1 2016-02-29 #&gt; gtable 0.2.0 2016-02-26 #&gt; highr 0.6 2016-05-09 #&gt; htmltools 0.3.5 2016-03-21 #&gt; htmlwidgets 0.7 2016-08-02 #&gt; httr 1.2.1 2016-07-03 #&gt; inline 0.3.14 2015-04-13 #&gt; jsonlite 1.2 2016-12-31 #&gt; knitr 1.15.1 2016-11-22 #&gt; labeling 0.3 2014-08-23 #&gt; lattice 0.20-34 2016-09-06 #&gt; lazyeval 0.2.0.9000 2016-09-19 #&gt; lme4 1.1-12 2016-04-16 #&gt; lubridate * 1.6.0.9009 2017-01-24 #&gt; magrittr 1.5 2014-11-22 #&gt; markdown 0.7.7 2015-04-22 #&gt; MASS 7.3-45 2016-04-21 #&gt; Matrix 1.2-7.1 2016-09-01 #&gt; MatrixModels 0.4-1 2015-08-22 #&gt; mgcv 1.8-15 2016-09-14 #&gt; mime 0.5 2016-07-07 #&gt; minqa 1.2.4 2014-10-09 #&gt; munsell 0.4.3 2016-02-13 #&gt; nlme 3.1-128 2016-05-10 #&gt; nloptr 1.0.4 2014-08-04 #&gt; nnet 7.3-12 2016-02-02 #&gt; openssl 0.9.4 2016-05-25 #&gt; pbkrtest 0.4-6 2016-01-27 #&gt; plyr 1.8.4.9000 2016-11-03 #&gt; portableParallelSeeds * 0.97 2016-11-14 #&gt; purrr * 0.2.2.9000 2016-11-22 #&gt; quantreg 5.29 2016-09-04 #&gt; R6 2.2.0 2016-10-05 #&gt; RColorBrewer 1.1-2 2014-12-07 #&gt; Rcpp 0.12.9.1 2017-01-24 #&gt; RcppEigen 0.3.2.9.0 2016-08-21 #&gt; reshape2 1.4.2 2016-10-22 #&gt; rmarkdown 1.3 2016-12-21 #&gt; rockchalk 1.8.101 2016-02-25 #&gt; rprojroot 1.1 2016-10-29 #&gt; rstan * 2.14.1 2016-12-28 #&gt; rvest * 0.3.2 2016-06-17 #&gt; scales 0.4.1 2016-11-09 #&gt; selectr 0.3-0 2016-08-30 #&gt; SparseM 1.72 2016-09-06 #&gt; StanHeaders * 2.14.0-1 2017-01-09 #&gt; stringi 1.1.2 2016-10-01 #&gt; stringr 1.1.0 2016-08-19 #&gt; tibble 1.2-15 2017-01-11 #&gt; xml2 * 1.0.0 2016-06-24 #&gt; yaml 2.1.14 2016-11-12 #&gt; source #&gt; CRAN (R 3.3.0) #&gt; cran (@1.0.4) #&gt; cran (@0.1-3) #&gt; cran (@1.62.0-) #&gt; CRAN (R 3.3.0) #&gt; Github (rstudio/bookdown@2211cd0) #&gt; CRAN (R 3.3.0) #&gt; cran (@1.17.1) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.0) #&gt; cran (@0.5-1) #&gt; CRAN (R 3.3.0) #&gt; cran (@0.6.11) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.0) #&gt; Github (hadley/ggplot2@2a1bf98) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.0) #&gt; cran (@0.6) #&gt; cran (@0.3.5) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.0) #&gt; cran (@1.2) #&gt; cran (@1.15.1) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.2) #&gt; Github (hadley/lazyeval@c155c3d) #&gt; CRAN (R 3.3.0) #&gt; Github (hadley/lubridate@ebd90d9) #&gt; CRAN (R 3.3.0) #&gt; cran (@0.7.7) #&gt; CRAN (R 3.3.2) #&gt; CRAN (R 3.3.2) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.2) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.2) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.2) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.0) #&gt; Github (hadley/plyr@fe19241) #&gt; CRAN (R 3.3.1) #&gt; Github (hadley/purrr@5360143) #&gt; CRAN (R 3.3.0) #&gt; cran (@2.2.0) #&gt; CRAN (R 3.3.0) #&gt; Github (RcppCore/Rcpp@5a99a86) #&gt; CRAN (R 3.3.0) #&gt; cran (@1.4.2) #&gt; cran (@1.3) #&gt; CRAN (R 3.3.0) #&gt; cran (@1.1) #&gt; CRAN (R 3.3.2) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.2) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.0) #&gt; CRAN (R 3.3.2) #&gt; CRAN (R 3.3.1) #&gt; cran (@1.1.0) #&gt; Github (hadley/tibble@3d6f8b4) #&gt; cran (@1.0.0) #&gt; cran (@2.1.14) References "],
["define-model.html", "2 Defining the Model 2.1 The bivariate Poisson model 2.2 The game random intercept model", " 2 Defining the Model In soccer, the goals scored by a single team can be thought of as coming from a Poisson distribution. Thus, we can state that the two scores from a given game, \\(X\\) and \\(Y\\), are Poisson distributed. \\[\\begin{equation} \\begin{split} X &amp; \\sim Poisson(\\lambda_1)\\\\ Y &amp; \\sim Poisson(\\lambda_2) \\end{split} \\tag{2.1} \\end{equation}\\] This parameterization, however, assumes that the scores \\(X\\) and \\(Y\\) are independent of each other. In this project, the aim is to model the association between the two Poisson distributed variables. There are two methods for modeling this association that will be examined. The first is a bivariate Poisson distribution. The second is a mixed effects model with a random slope for each game. 2.1 The bivariate Poisson model In the bivariate Poisson, the scores for teams \\(A\\) and \\(B\\), \\(X_A\\) and \\(X_B\\), are random variables where \\(G_i \\sim Poisson(\\lambda_i),\\ i = 0,\\ 1,\\ 2\\). \\[\\begin{equation} \\begin{split} X_A &amp; = G_1 + G_0\\\\ X_B &amp; = G_2 + G_0 \\end{split} \\tag{2.2} \\end{equation}\\] And \\(X_A\\) and \\(X_B\\) are jointly distributed \\[\\begin{equation} (X_A,\\ X_B) \\sim BP(\\lambda_1,\\ \\lambda_2,\\ \\lambda_0) \\tag{2.3} \\end{equation}\\] In this parameterization, \\(X_A\\) and \\(X_B\\) are Poisson distributed with means equal to \\(\\lambda_1 + \\lambda_3\\) and \\(\\lambda_2 + \\lambda_3\\) respectively, with \\(\\lambda_3\\) representing the covariance between \\(X_A\\) and \\(X_B\\) (AlMuhayfith, Alzaid, &amp; Omair, 2016; Griffiths &amp; Milne, 1978; Kawamura, 1973). We can model these parameters just as we would model, for example, means in a normal distribution. Thus, for a given game, \\(i\\), \\[\\begin{equation} \\begin{split} (X_{Ai},\\ X_{Bi}) &amp; \\sim BP(\\lambda_{1i},\\ \\lambda_{2i},\\ \\lambda_{0i}),\\\\ log(\\lambda_{1i}) &amp; = \\omega_{1i}\\beta_{1},\\\\ log(\\lambda_{2i}) &amp; = \\omega_{2i}\\beta_{2},\\\\ log(\\lambda_{0i}) &amp; = \\omega_{0i}\\beta_{0} \\end{split} \\tag{2.4} \\end{equation}\\] where \\(\\omega\\) represents a matrix of independent variable, and \\(\\beta\\) denotes the regression coefficients (Karlis &amp; Ntzoufras, 2003, 2005). When predicting soccer games, the independent variables are the teams that are playing, and the regression coefficients represent the offensive or defensive strength of the teams (Groll, Kneib, Mayr, &amp; Schauberger, 2016). Specifically, we can model the two scores, \\(X\\), for teams \\(A\\) and \\(B\\), from a given game, \\(i\\), as \\[\\begin{align} log(X_{Ai}) &amp;= \\lambda_{1i} + \\lambda_{0i}, \\notag \\\\ log(X_{Bi}) &amp;= \\lambda_{2i} + \\lambda_{0i}, \\notag \\\\ \\lambda_{1i} &amp;= \\mu + \\eta H_i + \\alpha_A + \\delta_B, \\tag{2.5} \\\\ \\lambda_{2i} &amp;= \\mu + \\alpha_B + \\delta_A, \\tag{2.6} \\\\ \\lambda_{0i} &amp;= \\rho_A + \\rho_B \\tag{2.7} \\end{align}\\] Here, \\(\\mu\\) denotes the overall intercept, or the expected log goals for a team not playing at home, and \\(\\eta\\) represents the increase in expected log goals for a team playing at home. \\(H_i\\) is a dummary variable indicating whether game \\(i\\) was played at the home team’s stadium (1) or a neutral site (0). The estimates of team ability come from \\(\\alpha\\) and \\(\\delta\\), which represent the attacking and defensive abilities of the given team respectively. These can be modeled as fixed effects, or as random effects. Finally, \\(\\rho\\) denotes the change in expected covariance for each team (Whitaker, 2011). 2.1.1 Implementing the bivariate Poisson model The bivariate Poisson model can be fit using the following Stan code and the rstan package (Guo, Gabry, &amp; Goodrich, 2016). In the model code, I have modeled \\(\\alpha\\), \\(\\delta\\), and \\(\\rho\\) as random effects so that \\(\\mu\\) represents the overall mean. This means that positive \\(\\alpha\\) values and negative \\(\\delta\\) are good, as team wants the attack to add goals above the average, and the defense to result in the opponent have below average goals. I have also reparameterized the random effects so that Stan can sample from a \\(\\mathcal{N}(0,\\ 1)\\), which reduces computation time and increases the efficiency of the sampler to avoid divergent transitions (Betancourt, 2016, 2017; Stan Development Team, 2016b). data { int&lt;lower=1&gt; num_clubs; // number of clubs int&lt;lower=1&gt; num_games; // number of games int&lt;lower=1,upper=num_clubs&gt; home[num_games]; // home club for game g int&lt;lower=1,upper=num_clubs&gt; away[num_games]; // away club for game g int&lt;lower=0&gt; h_goals[num_games]; // home goals for game g int&lt;lower=0&gt; a_goals[num_games]; // away goals for game g int&lt;lower=0,upper=1&gt; homeg[num_games]; // home field for game g } parameters { vector[num_clubs] raw_alpha; // attacking intercepts vector[num_clubs] raw_delta; // defending intercepts vector[num_clubs] raw_rho; // covariance intercepts real mu; // fixed intercept real eta; // homefield real&lt;lower=0&gt; sigma_a; // attacking sd real&lt;lower=0&gt; sigma_d; // defending sd real&lt;lower=0&gt; sigma_r; // covariance sd } transformed parameters { vector[num_clubs] alpha; vector[num_clubs] delta; vector[num_clubs] rho; alpha = raw_alpha * sigma_a; delta = raw_delta * sigma_d; rho = raw_rho * sigma_r; } model { vector[num_games] lambda1; vector[num_games] lambda2; vector[num_games] lambda3; // priors raw_alpha ~ normal(0, 1); raw_delta ~ normal(0, 1); raw_rho ~ normal(0, 1); mu ~ normal(0, 10); eta ~ normal(0, 10); sigma_a ~ normal(0, 10); sigma_d ~ normal(0, 10); sigma_r ~ normal(0, 10); // likelihood for (g in 1:num_games) { lambda1[g] = exp(mu + (eta * homeg[g]) + alpha[home[g]] + delta[away[g]]); lambda2[g] = exp(mu + alpha[away[g]] + delta[home[g]]); lambda3[g] = exp(rho[home[g]] + rho[away[g]]); } h_goals ~ poisson(lambda1 + lambda3); a_goals ~ poisson(lambda2 + lambda3); } 2.2 The game random intercept model As an alternative to the bivariate Poisson model, one could model a random intercept for each game, rather than estimating \\(\\rho\\). Thus, the game random intercept model would be defined as \\[\\begin{align} log(X_{Ai}) &amp;= \\lambda_{1i}, \\notag \\\\ log(X_{Bi}) &amp;= \\lambda_{2i}, \\notag \\\\ \\lambda_{1i} &amp;= \\mu + \\eta H_i + \\alpha_A + \\delta_B + \\gamma_i, \\tag{2.8} \\\\ \\lambda_{2i} &amp;= \\mu + \\alpha_B + \\delta_A + \\gamma_i \\tag{2.9} \\end{align}\\] This model is very similar to the bivariate Poisson. The two rate parameters, \\(\\lambda_{1i}\\) and \\(\\lambda_{2i}\\), are defined the same, with only the addition of \\(\\gamma_i\\) denoting the random intercept for the game. This \\(\\gamma_i\\) replaces \\(\\lambda_{0i}\\) in the bivariate Poisson model. This has a couple of downstream effects on the estimation. First, in the bivariate Poisson model, \\(\\rho\\) is estimated for each team. Thus the convariance, \\(\\lambda_{0i}\\) is predicted for each game by the competing teams’ \\(\\rho\\) values. This also allows predictions to be made for future games about what the covariance or dependency between the teams will be. In contrast, game random intercept model doesn’t estimate predictors for this dependency. In this model, the dependency is treated as a random variable, with some variance to be estimated. Thus, although both models take into account the dependency between the two scores in a given game, the models make different assumptions about the nature of this dependency. 2.2.1 Implementing the game random intercept model The game random intercept model can be estimated using the following Stan code and the rstan package (Guo et al., 2016). As with the bivariate Poisson model, I have modeled \\(\\alpha\\) and \\(\\delta\\) as random effects so that \\(\\mu\\) represents the overall mean. The random effects are also reparameterized in the same way as they were in the bivariate Poisson to reduce computation time and increase efficiency (Betancourt, 2016, 2017; Stan Development Team, 2016b). data { int&lt;lower=1&gt; num_clubs; // number of clubs int&lt;lower=1&gt; num_games; // number of games int&lt;lower=1,upper=num_clubs&gt; home[num_games]; // home club for game g int&lt;lower=1,upper=num_clubs&gt; away[num_games]; // away club for game g int&lt;lower=0&gt; h_goals[num_games]; // home goals for game g int&lt;lower=0&gt; a_goals[num_games]; // away goals for game g int&lt;lower=0,upper=1&gt; homeg[num_games]; // home field for game g } parameters { vector[num_clubs] raw_alpha; // attacking intercepts vector[num_clubs] raw_delta; // defending intercepts vector[num_games] raw_gamma; // game intercepts real mu; // fixed intercept real eta; // homefield real&lt;lower=0&gt; sigma_a; // attacking sd real&lt;lower=0&gt; sigma_d; // defending sd real&lt;lower=0&gt; sigma_g; // game sd } transformed parameters { vector[num_clubs] alpha; vector[num_clubs] delta; vector[num_games] gamma; alpha = sigma_a * raw_alpha; delta = sigma_d * raw_delta; gamma = sigma_g * raw_gamma; } model { vector[num_games] lambda1; vector[num_games] lambda2; // priors raw_alpha ~ normal(0, 1); // attacking random effects raw_delta ~ normal(0, 1); // defending random effects raw_gamma ~ normal(0, 1); // game random effects mu ~ normal(0, 10); eta ~ normal(0, 10); sigma_a ~ normal(0, 10); sigma_d ~ normal(0, 10); sigma_g ~ normal(0, 10); // likelihood for (g in 1:num_games) { lambda1[g] = exp(mu + (eta * homeg[g]) + alpha[home[g]] + delta[away[g]] + gamma[g]); lambda2[g] = exp(mu + alpha[away[g]] + delta[home[g]] + gamma[g]); } h_goals ~ poisson(lambda1); a_goals ~ poisson(lambda2); } References "],
["simulation.html", "3 Simulation Study 3.1 Data generation 3.2 Model estimation 3.3 Running the simulation 3.4 Simulation results 3.5 Summary of findings {sim-concl}", " 3 Simulation Study In order to evaluate these two models, I conducted a small scale simulation study. I generated 100 data sets from each of the bivariate Poisson and game random intercept models (for 200 data sets total). For each data set, both of the models were estimated to determine how well they were able to recover the attacking and defensive parameters for each team when the data generating model did and did not match the model. 3.1 Data generation Data was simulated to mimic the major domestic European leagues. For each data set, 20 clubs were generated, with each club playing all other clubs twice, once at home, and once away, for a total of 380 games. For both data generating models, \\(\\alpha\\) and \\(\\delta\\) parameters were drawn from a \\(\\mathcal{N}(0,0.35)\\). Both \\(\\rho\\) in the bivariate Poisson and \\(\\gamma\\) in the game random intercept model were sampled from a \\(\\mathcal{N}(0,0.1)\\) distribution. For all models, \\(\\mu\\) was set to 0, and \\(\\eta\\) was set to 0.5. These distributions were based on preliminary analyses using the 2015-16 English Premier League data. For each game, \\(\\lambda\\) values were calculated based on the parameters that were generated for each team (and game for the game random intercept model). Scores were then randomly generated using the rpois() function. Full data generation functions can be see in Appendix A.1 and A.2. When simulating the data sets, the portableParallelSeeds package was used to ensure that the data generation was completely replicable, and that the random number streams were not overlapping (Johnson, 2016). 3.2 Model estimation In total, 200 data sets were generated: 100 from the bivariate Poisson, and 100 from the game random intercept model. For each data set, both the bivariate Poisson and game random intercept model were estimated. Thus, each model was estimated 100 times on a data set from the matching data generation method, and 100 times on mismatched data. For each estimation, 2 chains were run with 15000 iterations. The first 5000 iterations of each chain were discarded for burn-in. This resulted in a total of 20000 retained iterations that made up the final posterior distributions. The thinning interval was set to 1 (no thinning). Finally, the target proposal acceptance rate during the adaptation period was set to 0.99. This forces the algorithm to take smaller steps, which decreases efficiency. However, this also helps to eliminate divergent transitions, which are common when parameter estimates are close to their bounds, such as a variance very close to 0 (Stan Development Team, 2016b, 2016a). The full model estimation function can be seen in Appendix A.3. 3.3 Running the simulation The following code was used to run the simulation. I first define the total number of replications and the number of random streams needed for each replication. I then use portableParallelSeeds (Johnson, 2016) to create seeds for each replication, and save them. Data sets are then generated from each model, with the number of data sets from each model being equal to half of the total number of replications specified by n_reps. Finally, I create one list that contains all of the data sets, simulation_data, and map the simulation function to each element of that list using the purrr package (Wickham, 2016b). # Define parameters for the simulation n_reps &lt;- 200 streams_per_rep &lt;- 1 # Create the seed warehouse project_seeds &lt;- seedCreator(n_reps, streams_per_rep, seed = 9416) save(project_seeds, file = &quot;_data/simulation_seeds.rda&quot;) # Create data sets bivpois_data &lt;- lapply(X = 1:(n_reps / 2), FUN = generate_bivpois, seeds = project_seeds, num_club = 20) gri_data &lt;- lapply(X = ((n_reps / 2) + 1):n_reps, FUN = generate_gri, seeds = project_seeds, num_club = 20) simulation_data &lt;- c( bivpois_data, gri_data ) simulation &lt;- map_df(.x = simulation_data, .f = simulation_fun) save(simulation, file = &quot;_data/simulation.rda&quot;) 3.4 Simulation results 3.4.1 Correlation between true and estimated parameters To assess the bivariate Poisson and game random intercept models, I first examine the correlations between the true parameters and the estimated parameters from each model. The parameters for each replication can be pulled out of the simulation results using the purrr and dplyr packages (Wickham, 2016b; Wickham &amp; Francois, 2016). The plyr package will be used later but, for compatibility reasons, needs to be loaded before dplyr. library(plyr) library(dplyr) library(purrr) plot_sim &lt;- simulation %&gt;% select(generator, true_params, bivpois_params, gri_params) %&gt;% as.list() %&gt;% pmap_df(.l = ., .f = function(generator, true_params, bivpois_params, gri_params) { data_frame( generator = generator, true_alpha = true_params$attack, true_delta = true_params$defend, bivpois_alpha = bivpois_params$bivpois_alpha, bivpois_delta = bivpois_params$bivpois_delta, gri_alpha = gri_params$gri_alpha, gri_delta = gri_params$gri_delta ) }) I then use the GGally package (Schloerke et al., 2016), an extension of ggplot2 (Wickham &amp; Chang, 2016) to plot a scatter plot matrix with correlations. I use the round_any() function from the plyr package (Wickham, 2016a) to set the limits on the axes. The functions to create the lower and upper triangles and the diagonal of the scatter plot matrix (lowerFn(), upperFn(), and diagFn() respectively) can be found in Appendix A.4.1, and the code to put the plots together can be found in Appendix A.4.2. Figure 3.1: Correlation between true and estimated alpha parameters under different generating and estimated models. Figure 3.2: Correlation between true and estimated delta parameters under different generating and estimated models. In the Figures 3.1 and 3.2, the margins show which model was estimated. The upper triangle shows the correlations between the estimated parameters for the model and the true parameters under each of the data generation conditions. For example, when estimating the alpha parameters with the bivariate Poisson (Figure 3.1), the correlation between estimated parameters and true parameters is 0.831 when the data was generated with the GRI model and 0.832 when generated with the bivariate Poisson model. When looking at Figures 3.1 and 3.2, the correlation between true and estimated parameters is higher when the game random intercept model is used for estimation compared to the bivariate Poisson. This is true when the game random intercept model is used to generate data (0.907 to 0.831 for alpha and 0.903 to 0.821 for delta) and when the bivariate Poisson model is use for data generation (0.847 to 0.832 for alpha and 0.861 to 0.849 for delta). Thus, this provides preliminary evidence that the game random intercept model should be preferred. 3.4.2 Estimation bias and mean square error It is also useful to look at the average bias and mean squared error of the estimates from each model. Table 3.1 shows the average bias in the estimates for alpha and delta (calculated as \\(estimate - true\\)). simulation %&gt;% select(`Data Generator` = generator, bivpois_alpha_bias, bivpois_delta_bias, gri_alpha_bias, gri_delta_bias) %&gt;% group_by(`Data Generator`) %&gt;% summarize( `Bivariate Poisson: Alpha` = sprintf(&quot;%.3f&quot;, mean(bivpois_alpha_bias)), `Bivariate Poisson: Delta` = sprintf(&quot;%.3f&quot;, mean(bivpois_delta_bias)), `Game Random Intercept: Alpha` = sprintf(&quot;%.3f&quot;, mean(gri_alpha_bias)), `Game Random Intercept: Delta` = sprintf(&quot;%.3f&quot;, mean(gri_delta_bias)) ) %&gt;% mutate(`Data Generator` = factor(`Data Generator`, levels = c(&quot;bivpois&quot;, &quot;gri&quot;), labels = c(&quot;Bivariate Poisson&quot;, &quot;Game Random Intercept&quot;))) %&gt;% knitr::kable(caption = &quot;Estimation bias for alpha and delta parameters.&quot;) Table 3.1: Estimation bias for alpha and delta parameters. Data Generator Bivariate Poisson: Alpha Bivariate Poisson: Delta Game Random Intercept: Alpha Game Random Intercept: Delta Bivariate Poisson 0.001 -0.012 0.001 -0.012 Game Random Intercept -0.010 -0.003 -0.010 -0.002 The bias is nearly identical across estimation models, regardless of which model was used for data generation. Further, all of the biases are very close to 0, indicating that neither model significantly biases the estimates in a positive or negative way. Table 3.2 shows the average mean square error in the estimates for alpha and delta (calculated as \\((estimate - true)^2\\)). simulation %&gt;% select(`Data Generator` = generator, bivpois_alpha_mse, bivpois_delta_mse, gri_alpha_mse, gri_delta_mse) %&gt;% group_by(`Data Generator`) %&gt;% summarize( `Bivariate Poisson: Alpha` = sprintf(&quot;%.3f&quot;, mean(bivpois_alpha_mse)), `Bivariate Poisson: Delta` = sprintf(&quot;%.3f&quot;, mean(bivpois_delta_mse)), `Game Random Intercept: Alpha` = sprintf(&quot;%.3f&quot;, mean(gri_alpha_mse)), `Game Random Intercept: Delta` = sprintf(&quot;%.3f&quot;, mean(gri_delta_mse)) ) %&gt;% mutate(`Data Generator` = factor(`Data Generator`, levels = c(&quot;bivpois&quot;, &quot;gri&quot;), labels = c(&quot;Bivariate Poisson&quot;, &quot;Game Random Intercept&quot;))) %&gt;% knitr::kable(caption = &quot;Estimation mean square error for alpha and delta parameters.&quot;) Table 3.2: Estimation mean square error for alpha and delta parameters. Data Generator Bivariate Poisson: Alpha Bivariate Poisson: Delta Game Random Intercept: Alpha Game Random Intercept: Delta Bivariate Poisson 0.038 0.037 0.046 0.049 Game Random Intercept 0.083 0.069 0.022 0.022 As would be expected, there is more error associated with estimates coming from a model that doesn’t match the data generating model. However, comparatively, there is less error associated with the game random intercept model. When the estimation model matches the generation model, the game random intercept model has mean square error values of 0.022 and 0.022 for alpha and delta parameters respectively. The bivariate Poisson model has mean square error values of 0.038 and 0.037 for these same parameters. Similarly, the game random intercept model also shows lower error when the estimation model doesn’t match the generation model. The game random intercept model has mean square error values for alpha and delta of 0.046 and 0.049 when the bivariate Poisson generated the data, whereas the bivariate Poisson has mean square error values for alpha and delta of 0.083 and 0.069 when the game random intercept model generated the data. These results indicate that the best choice of model would be the one that matches the data generation process. Unfortunately, when using real data, the exact data generation process is impossible to know. However, these findings also show that the cost of being wrong is much less when using the game random intercept model to estimate, compared to the bivariate Poisson model. 3.5 Summary of findings {sim-concl} The findings from the simulation study indicate that the game random intercept model should be the preferred model for estimating the abilities of soccer teams. Across data generating models, the game random intercept model was better able to recover the true parameters (Section 3.4.1). Additionally, the game random intercept model had comparable bias and lower mean square error than the the bivariate Poisson model (Section 3.4.2). Therefore, I will be using the game random intercept model moving forward for estimating the model on real data and predicting future games. References "],
["gather-data.html", "4 Gather Data 4.1 Domestic league inclusion 4.2 Non-domestic competition inclusion 4.3 Domestic competition inclusion 4.4 Collect club websites 4.5 Scrape game data", " 4 Gather Data Perhaps the most important part of any data analysis is the collection of the data. If you don’t have the data necessary to support the model you want to estimate, or the conclusions you want to draw, no amount of tinkering with the model or results can save you. The data for this project was collected using web scraping via the rvest (Wickham, 2016c) and dplyr (Wickham &amp; Francois, 2016) packages. The scores for each game in a season for a given team can be found on ESPN’s website. For example, all of Barcelona’s games can be found here. Given that there is access to the results for any team available on ESPN, the question becomes which teams to include in the analysis. I chose teams that particpated in specific domestic leagues or in certain tournaments or competitions. The rationale for each selection is below. 4.1 Domestic league inclusion Because one goal of the project was to predict the 5 major European domestic leagues, all teams from the English Premier League, German Bundesliga, French Ligue 1, Spanish La Liga, and Italian Serie A were included. I also included the second tier leagues from these countries, if they were available. This included the English League Championship, German 2. Bundesliga, French Ligue 2, and Italian Serie B. The other major goal was to predict the UEFA Champion’s League (UCL). Many of the UCL teams come from the major domestic leagues, however many teams do not. Thus, I also included teams from the Belgian Jupiler League, Danish SAS-Ligaen, Dutch Eredivisie, Portuguese Liga, Russian Premier League, Scottish Premiership, Swiss Super League, and Turkish Super Lig. These leagues were selected because they all had teams reach the knockout stage of the UCL, and thus would have sufficient crossover with the major leagues. To get the URLs for each team, I’ll write a function that uses the rvest package to pull hyperlinks of of the league pages called scrape_league(). This function takes in a URL for a given league, and returns a data frame with the club names, the totals goals scored by and against each club in league play, the points each club has accumulated, and the club’s URL. See Appendix B.1 for the full function. For a full description of how the rvest package works, see this webinar (Grolemund, 2016). 4.2 Non-domestic competition inclusion Although many of the teams participating in the UCL come from the leagues the leagues outlines above, not all due. A few come from smaller leagues that are not covered by ESPN. Thus, all teams that participated in the group stage of the UCL were included. Additionally, teams that didn’t qualify for the UCL, and some teams that did qualify for the UCL, but didn’t make it out of the group stage, play in the second tier Eurpoa League tournament. Because this tournament includes more overlap between the leagues, all teams participating in the Europa league were also included. Finally, the International Champions Cup is a relatively new event that pairs top teams from Europe against each other around the world. All participants in this event were also included. The webpages for these competitions are formatted slightly differently than those for the domestic leagues, so I will need a slightly different function to scrape these team URLs, scrape_major_cup() (see Appendix B.2). Unlike the league scraper, this function only returns the club, and the URL for the club. 4.3 Domestic competition inclusion Finally, in addition to domestic leagues and international club competitions, European teams also compete in domestic tournaments. These competitions were also included to increase the number of data points for the top teams, as well as to increase the overlap between the first and second tier leagues of the top countries. All participants were included from Spain’s Copa del Ray and Spanish Super Cup, Italy’s Coppa Italia, France’s Coupe de France and Coupe de la Ligue, Germany’s DFB Pokal, and England’s FA Cup and League Cup. These webpages are also formatted differently, so I have one final function to get the team URLs, scrape_dom_cup() (see Appendix B.3). As with the scraper for the international competitions, this scraper also returns the club name and club URL. 4.4 Collect club websites Now that criteria for which teams will be included has been defined, the purrr package (Wickham, 2016b) can be used to map the each function the corresponding league or competition URL. For more information on the purrr package see R for Data Science (Wickham &amp; Grolemund, 2016). First I’ll create a list of URLs for each type of scraper. leagues &lt;- list( belgium = &quot;http://www.espnfc.us/belgian-jupiler-league/6/table&quot;, denmark = &quot;http://www.espnfc.us/danish-sas-ligaen/7/table&quot;, england = &quot;http://www.espnfc.us/english-premier-league/23/table&quot;, england2 = &quot;http://www.espnfc.us/english-league-championship/24/table&quot;, france = &quot;http://www.espnfc.us/french-ligue-1/9/table&quot;, france2 = &quot;http://www.espnfc.us/french-ligue-2/96/table&quot;, germany = &quot;http://www.espnfc.us/german-bundesliga/10/table&quot;, germany2 = &quot;http://www.espnfc.us/german-2-bundesliga/97/table&quot;, italy = &quot;http://www.espnfc.us/italian-serie-a/12/table&quot;, italy2 = &quot;http://www.espnfc.us/italian-serie-b/99/table&quot;, netherlands = &quot;http://www.espnfc.us/dutch-eredivisie/11/table&quot;, portugal = &quot;http://www.espnfc.us/portuguese-liga/14/table&quot;, russia = &quot;http://www.espnfc.us/russian-premier-league/106/table&quot;, scotland = &quot;http://www.espnfc.us/scottish-premiership/45/table&quot;, spain = &quot;http://www.espnfc.us/spanish-primera-division/15/table&quot;, switzerland = &quot;http://www.espnfc.us/swiss-super-league/17/table&quot;, turkey = &quot;http://www.espnfc.us/turkish-super-lig/18/table&quot; ) major_cups &lt;- list( champions_league = &quot;http://www.espnfc.us/uefa-champions-league/2/table&quot;, europa_league = &quot;http://www.espnfc.us/uefa-europa-league/2310/table&quot;, icc = &quot;http://www.espnfc.us/international-champions-cup/2326/table&quot; ) domestic_cups &lt;- list( copa_del_rey = &quot;http://www.espnfc.us/spanish-copa-del-rey/80/statistics/fairplay&quot;, coppa_italia = &quot;http://www.espnfc.us/italian-coppa-italia/2192/statistics/fairplay&quot;, coupe_de_france = &quot;http://www.espnfc.us/french-coupe-de-france/182/statistics/fairplay&quot;, coupe_de_la_ligue = &quot;http://www.espnfc.us/french-coupe-de-la-ligue/159/statistics/fairplay&quot;, dfb_pokal = &quot;http://www.espnfc.us/german-dfb-pokal/2061/statistics/fairplay&quot;, efl_cup = &quot;http://www.espnfc.us/efl-cup/41/statistics/fairplay&quot;, fa_cup = &quot;http://www.espnfc.us/english-fa-cup/40/statistics/fairplay&quot;, spanish_super_cup = &quot;http://www.espnfc.us/spanish-super-cup/431/statistics/fairplay&quot; ) Then I can then map the functions to the defined URLs. Because there are many teams to scrape, it’s possible to overload ESPN’s server request limit. Therefore, I’ve define a safe version of the read_html() function that will allow us to check if the website was read correctly. library(rvest) library(purrr) library(dplyr) safe_read_html &lt;- safely(read_html) league_urls &lt;- map_df(.x = leagues, .f = scrape_league) major_cup_urls &lt;- map_df(.x = major_cups, .f = scrape_major_cup) domestic_cup_urls &lt;- map_df(.x = domestic_cups, .f = scrape_dom_cup) The next step is to create a data frame of all the clubs and their URLs. Many teams participate in multiple competitions that were included, so only one instance will be kept. url_lookup &lt;- list( select(league_urls, club, club_url), major_cup_urls, domestic_cup_urls ) %&gt;% bind_rows() %&gt;% filter(!is.na(club_url)) %&gt;% unique() full_urls &lt;- league_urls %&gt;% select(-club_url) %&gt;% full_join(url_lookup, by = &quot;club&quot;) %&gt;% filter(!is.na(club_url)) DT::datatable(full_urls, options = list(pageLength = 5, scrollX = TRUE), rownames = FALSE) 4.5 Scrape game data Now that all of the team URLs have been collected, I can scrape the game data from each team’s page on ESPN. To do this, I’ll define a new scraper function, scrape_team() (see Appendix B.4). Then this function gets mapped to all of the club URLs, using the same process that was used for the league URLs. Note that I also use the lubridate package (Grolemund, Spinu, &amp; Wickham, 2016) to format dates within the scrape_team() function. library(lubridate) full_data &lt;- map2_df(.x = full_urls$club_url, .y = full_urls$club, .f = scrape_team) Finally, there is just little cleaning to be done. I will remove duplicate games, and replace the abbreviations that ESPN uses in their scores with the full club name. team_lookup &lt;- select(full_data, -team_data) full_data &lt;- bind_rows(full_data$team_data) %&gt;% unique() %&gt;% arrange(date, home) %&gt;% left_join(select(full_data, -team_data), by = c(&quot;home&quot; = &quot;abbrev&quot;)) %&gt;% rename(home_club = club) %&gt;% left_join(select(full_data, -team_data), by = c(&quot;away&quot; = &quot;abbrev&quot;)) %&gt;% rename(away_club = club) %&gt;% mutate( real_home = ifelse(is.na(home_club), home, home_club), real_away = ifelse(is.na(away_club), away, away_club), home = real_home, away = real_away ) %&gt;% select(-(home_club:real_away)) %&gt;% mutate(home_game = ifelse(competition %in% c(&quot;Champions Cup&quot;), 0, 1)) %&gt;% filter(!(date &lt; Sys.Date() &amp; is.na(home_goals))) %&gt;% filter(date &gt; ymd(&quot;2016-03-01&quot;)) %&gt;% rename(h_goals = home_goals, a_goals = away_goals) DT::datatable(full_data, options = list(pageLength = 5, scrollX = TRUE)) References "],
["fit-model.html", "5 Fitting the Model 5.1 MCMC diagnostics 5.2 Model fit 5.3 Results", " 5 Fitting the Model library(dplyr) library(rstan) load(&quot;_data/full_data.rda&quot;) fit_data &lt;- full_data %&gt;% filter(!is.na(h_goals)) filter_games &lt;- TRUE while(filter_games) { team_counts &lt;- table(c(fit_data$home, fit_data$away)) %&gt;% as_data_frame() %&gt;% arrange(desc(n)) %&gt;% filter(n &gt;= 5) %&gt;% select(team = Var1) %&gt;% arrange(team) %&gt;% mutate(code = seq_len(nrow(.))) fit_data &lt;- fit_data %&gt;% select(-competition) %&gt;% left_join(team_counts, by = c(&quot;home&quot; = &quot;team&quot;)) %&gt;% rename(home_code = code) %&gt;% left_join(team_counts, by = c(&quot;away&quot; = &quot;team&quot;)) %&gt;% rename(away_code = code) %&gt;% filter(!is.na(home_code), !is.na(away_code)) new_min &lt;- table(c(fit_data$home, fit_data$away)) %&gt;% as.numeric() %&gt;% min() if (new_min &gt;= 5) { filter_games &lt;- FALSE } } stan_data &lt;- list( num_clubs = nrow(team_counts), num_games = nrow(fit_data), home = fit_data$home_code, away = fit_data$away_code, h_goals = fit_data$h_goals, a_goals = fit_data$a_goals, homeg = fit_data$home_game ) gri &lt;- stan(file = &quot;_data/stan-models/gri.stan&quot;, data = stan_data, chains = 3, iter = 15000, warmup = 5000, init = &quot;random&quot;, thin = 1, cores = 3, control = list(adapt_delta = 0.99)) sp &lt;- get_sampler_params(gri, inc_warmup = FALSE) E &lt;- as.matrix(sapply(sp, FUN = function(x) x[,&quot;energy__&quot;])) EBFMI &lt;- get_num_upars(gri) / apply(E, 2, var) 5.1 MCMC diagnostics 5.1.1 Convergence Rhat geweke (ggmcmc) running means autocorrelation 5.1.2 Efficiency mean accept stat max tree depth (should be &lt; 10, the default value) BFMI 5.2 Model fit posterior predictive checks * distribution of scores * distribution of MOV * correct predictions 5.3 Results "],
["predict.html", "6 Making Predictions", " 6 Making Predictions "],
["conclusion.html", "7 Conclusion 7.1 Limitations of the current approach 7.2 Future Directions", " 7 Conclusion 7.1 Limitations of the current approach 7.2 Future Directions "],
["simulation-functions.html", "A Simulation Functions A.1 Generate bivariate Poisson A.2 Generate game random intercept A.3 Fit models to simualted data A.4 Plot correlation matrices", " A Simulation Functions A.1 Generate bivariate Poisson generate_bivpois &lt;- function(run, seeds, num_club) { setSeeds(seeds, run = run) teams &lt;- data_frame( club = paste0(&quot;club&quot;, sprintf(&quot;%02d&quot;, seq_len(num_club))), attack = rnorm(n = num_club, mean = 0, sd = 0.35), defend = rnorm(n = num_club, mean = 0, sd = 0.35), cov = rnorm(n = num_club, mean = 0, sd = 0.1) ) games &lt;- teams %&gt;% select(club) %&gt;% flatten_chr() %&gt;% crossing(., .) colnames(games) &lt;- c(&quot;home&quot;, &quot;away&quot;) games &lt;- games %&gt;% filter(home != away) %&gt;% left_join(teams, by = c(&quot;home&quot; = &quot;club&quot;)) %&gt;% rename(h_att = attack, h_def = defend, h_cov = cov) %&gt;% left_join(teams, by = c(&quot;away&quot; = &quot;club&quot;)) %&gt;% rename(a_att = attack, a_def = defend, a_cov = cov) %&gt;% mutate( lambda1 = exp(0 + 0.5 + h_att + a_def), lambda2 = exp(0 + a_att + h_def), lambda3 = exp(h_cov + a_cov), h_goals = rpois(n = nrow(.), lambda = (lambda1 + lambda3)), a_goals = rpois(n = nrow(.), lambda = (lambda2 + lambda3)), home_game = 1 ) %&gt;% select(home, away, h_goals, a_goals, home_game) list( method = &quot;bivpois&quot;, teams = teams, games = games ) } A.2 Generate game random intercept generate_gri &lt;- function(run, seeds, num_club) { setSeeds(seeds, run = run) teams &lt;- data_frame( club = paste0(&quot;club&quot;, sprintf(&quot;%02d&quot;, seq_len(num_club))), attack = rnorm(n = num_club, mean = 0, sd = 0.35), defend = rnorm(n = num_club, mean = 0, sd = 0.35) ) games &lt;- teams %&gt;% select(club) %&gt;% flatten_chr() %&gt;% crossing(., .) colnames(games) &lt;- c(&quot;home&quot;, &quot;away&quot;) games &lt;- games %&gt;% filter(home != away) %&gt;% left_join(teams, by = c(&quot;home&quot; = &quot;club&quot;)) %&gt;% rename(h_att = attack, h_def = defend) %&gt;% left_join(teams, by = c(&quot;away&quot; = &quot;club&quot;)) %&gt;% rename(a_att = attack, a_def = defend) %&gt;% mutate( gamma = rnorm(n = nrow(.), mean = 0, sd = 0.1), lambda1 = exp(0 + 0.5 + h_att + a_def + gamma), lambda2 = exp(0 + a_att + h_def + gamma), h_goals = rpois(n = nrow(.), lambda = (lambda1)), a_goals = rpois(n = nrow(.), lambda = (lambda2)), home_game = 1 ) %&gt;% select(home, away, h_goals, a_goals, home_game) list( method = &quot;gri&quot;, teams = teams, games = games ) } A.3 Fit models to simualted data simulation_fun &lt;- function(x) { team_codes &lt;- data_frame( club = sort(unique(c(x$games$home, x$games$away))) ) %&gt;% mutate(code = seq_len(nrow(.))) fit_data &lt;- left_join(x$games, team_codes, by = c(&quot;home&quot; = &quot;club&quot;)) %&gt;% rename(home_code = code) %&gt;% left_join(team_codes, by = c(&quot;away&quot; = &quot;club&quot;)) %&gt;% rename(away_code = code) stan_data &lt;- list( num_clubs = nrow(team_codes), num_games = nrow(fit_data), home = fit_data$home_code, away = fit_data$away_code, h_goals = fit_data$h_goals, a_goals = fit_data$a_goals, homeg = fit_data$home_game ) bivpois &lt;- stan(file = &quot;_data/stan-models/biv_pois.stan&quot;, data = stan_data, chains = 2, iter = 15000, warmup = 5000, init = &quot;random&quot;, thin = 1, cores = 2, control = list(adapt_delta = 0.99)) gri &lt;- stan(file = &quot;_data/stan-models/gri.stan&quot;, data = stan_data, chains = 2, iter = 15000, warmup = 5000, init = &quot;random&quot;, thin = 1, cores = 2, control = list(adapt_delta = 0.99)) bivpois_maxrhat &lt;- as.data.frame(summary(bivpois)[[1]]) %&gt;% select(Rhat) %&gt;% flatten_dbl() %&gt;% max() gri_maxrhat &lt;- as.data.frame(summary(gri)[[1]]) %&gt;% select(Rhat) %&gt;% flatten_dbl() %&gt;% max() bivpois_params &lt;- rstan::extract(bivpois, pars = c(&quot;mu&quot;, &quot;eta&quot;, &quot;alpha&quot;, &quot;delta&quot;, &quot;rho&quot;)) gri_params &lt;- rstan::extract(gri, pars = c(&quot;mu&quot;, &quot;eta&quot;, &quot;alpha&quot;, &quot;delta&quot;)) bivpois_alpha &lt;- colMeans(bivpois_params$alpha) bivpois_delta &lt;- colMeans(bivpois_params$delta) gri_alpha &lt;- colMeans(gri_params$alpha) gri_delta &lt;- colMeans(gri_params$delta) bivpois_alpha_bias &lt;- mean(bivpois_alpha - x$teams$attack) bivpois_delta_bias &lt;- mean(bivpois_delta - x$teams$defend) bivpois_alpha_mse &lt;- mean((bivpois_alpha - x$teams$attack)^2) bivpois_delta_mse &lt;- mean((bivpois_delta - x$teams$defend)^2) gri_alpha_bias &lt;- mean(gri_alpha - x$teams$attack) gri_delta_bias &lt;- mean(gri_delta - x$teams$defend) gri_alpha_mse &lt;- mean((gri_alpha - x$teams$attack)^2) gri_delta_mse &lt;- mean((gri_delta - x$teams$defend)^2) data_frame( generator = x$method, true_params = list(x$teams), bivpois_rhat = bivpois_maxrhat, bivpois_params = list(list(bivpois_alpha = bivpois_alpha, bivpois_delta = bivpois_delta)), bivpois_alpha_bias = bivpois_alpha_bias, bivpois_delta_bias = bivpois_delta_bias, bivpois_alpha_mse = bivpois_alpha_mse, bivpois_delta_mse = bivpois_delta_mse, gri_rhat = gri_maxrhat, gri_params = list(list(gri_alpha = gri_alpha, gri_delta = gri_delta)), gri_alpha_bias, gri_delta_bias, gri_alpha_mse, gri_delta_mse ) } A.4 Plot correlation matrices A.4.1 Plot components lowerFn &lt;- function(data, mapping, ..., alpha = 0.5, lim = 2) { p &lt;- ggplot(data = data, mapping = mapping) + geom_point(..., alpha = alpha) + geom_abline(intercept = 0, slope = 1, color = &quot;black&quot;) + scale_x_continuous(limits = c(-lim, lim), breaks = seq(-lim, lim, 1)) + scale_y_continuous(limits = c(-lim, lim), breaks = seq(-lim, lim, 1)) + theme_bw() p } diagFn &lt;- function(data, mapping, ..., alpha = 0.5, lim = 2) { p &lt;- ggplot(data = data, mapping = mapping) + geom_density(..., alpha = alpha) + scale_x_continuous(limits = c(-lim, lim), breaks = seq(-lim, lim, 1)) + theme_bw() + theme(axis.ticks.y = element_blank(), axis.text.y = element_blank()) p } upperFn &lt;- function(data, mapping, ..., size = 3, lim = 2) { xCol &lt;- deparse(mapping$x) yCol &lt;- deparse(mapping$y) colorCol &lt;- deparse(mapping$colour) xVal &lt;- data[[xCol]] yVal &lt;- data[[yCol]] cVal &lt;- data[[colorCol]] plot_data &lt;- data_frame(xVal, yVal, cVal) %&gt;% group_by(cVal) %&gt;% summarize(corr = cor(xVal, yVal, method = &quot;pearson&quot;)) %&gt;% mutate( cVal = factor(cVal, levels = c(&quot;gri&quot;, &quot;bivpois&quot;), labels =c(&quot;GRI&quot;, &quot;Biv Poisson&quot;)), lab = paste0(cVal, &quot;: &quot;, sprintf(&quot;%.3f&quot;, corr)), y_pos = 1:2, x_pos = 0 ) p &lt;- ggplot(data = plot_data, aes(x = x_pos, y = y_pos, fill = cVal, label = lab)) + geom_label(color = &quot;white&quot;, fontface = &quot;bold&quot;, size = size) + scale_x_continuous(limits = c(-lim, lim), breaks = seq(-lim, lim, 1)) + scale_y_continuous(limits = c(0, 3)) + scale_fill_manual(values = c(`Biv Poisson` = &quot;#F8766D&quot;, GRI = &quot;#00BFC4&quot;)) + theme_bw() + theme( legend.position = &quot;none&quot; ) p } get_lim &lt;- function(data) { data %&gt;% as.list() %&gt;% flatten_dbl() %&gt;% abs() %&gt;% max() %&gt;% round_any(accuracy = 0.5, f = ceiling) } A.4.2 Plot creation lim &lt;- get_lim(select(plot_sim, -generator)) ggpairs( title = &quot;Alpha Recovery&quot;, data = plot_sim, columns = c(&quot;true_alpha&quot;, &quot;bivpois_alpha&quot;, &quot;gri_alpha&quot;), mapping = aes(color = generator, fill = generator), columnLabels = c(&quot;True&quot;, &quot;Bivariate Poisson&quot;, &quot;Game Random Intercept&quot;), upper = list(continuous = wrap(upperFn, size = 3, lim = lim)), lower = list(continuous = wrap(lowerFn, alpha = 0.1, lim = lim)), diag = list(continuous = wrap(diagFn, alpha = 0.5, lim = lim)) ) ggpairs( title = &quot;Delta Recovery&quot;, data = plot_sim, columns = c(&quot;true_delta&quot;, &quot;bivpois_delta&quot;, &quot;gri_delta&quot;), mapping = aes(color = generator, fill = generator), columnLabels = c(&quot;True&quot;, &quot;Bivariate Poisson&quot;, &quot;Game Random Intercept&quot;), upper = list(continuous = wrap(upperFn, size = 3, lim = lim)), lower = list(continuous = wrap(lowerFn, alpha = 0.1, lim = lim)), diag = list(continuous = wrap(diagFn, alpha = 0.5, lim = lim)) ) "],
["scrape-functions.html", "B Web Scraping Functions B.1 Scrape league pages B.2 Scrape international cups B.3 Scrape domestic cups B.4 Scrape games", " B Web Scraping Functions B.1 Scrape league pages scrape_league &lt;- function(x) { cont &lt;- TRUE while(cont) { url_data &lt;- safe_read_html(x) if(is.null(url_data[[1]])) { closeAllConnections() Sys.sleep(5) } else { url_data &lt;- url_data[[1]] cont &lt;- FALSE } } league_table &lt;- url_data %&gt;% html_nodes(css = &quot;table&quot;) %&gt;% html_table() league_table &lt;- league_table[[1]] colnames(league_table) &lt;- as.character(league_table[1,]) colnames(league_table) &lt;- make.names(colnames(league_table), unique = TRUE) league_table &lt;- league_table[-1,] league_table &lt;- league_table %&gt;% select(club = TEAM, goals_for = `F`, goals_against = A, points = PTS) %&gt;% mutate(club = trimws(club, which = &quot;both&quot;)) teams &lt;- url_data %&gt;% html_nodes(&quot;td a&quot;) %&gt;% html_text() %&gt;% as.character() %&gt;% trimws(which = &quot;both&quot;) team_urls &lt;- url_data %&gt;% html_nodes(&quot;td a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% as.character() league_table &lt;- league_table %&gt;% left_join(data_frame(club = teams, club_url = team_urls), by = &quot;club&quot;) %&gt;% as_data_frame() return(league_table) } B.2 Scrape international cups scrape_major_cup &lt;- function(x) { cont &lt;- TRUE while(cont) { url_data &lt;- safe_read_html(x) if(is.null(url_data[[1]])) { closeAllConnections() Sys.sleep(5) } else { url_data &lt;- url_data[[1]] cont &lt;- FALSE } } league_table &lt;- url_data %&gt;% html_nodes(css = &quot;table&quot;) %&gt;% html_table() league_table &lt;- map_df(.x = league_table, .f = function(x) { colnames(x) &lt;- as.character(x[1,]) colnames(x) &lt;- make.names(colnames(x), unique = TRUE) x &lt;- x[-1,] x &lt;- x %&gt;% select(club = TEAM) return(x) }) %&gt;% bind_rows() %&gt;% mutate(club = trimws(club, which = &quot;both&quot;)) teams &lt;- url_data %&gt;% html_nodes(&quot;td a&quot;) %&gt;% html_text() %&gt;% as.character() %&gt;% trimws(which = &quot;both&quot;) team_urls &lt;- url_data %&gt;% html_nodes(&quot;td a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% as.character() league_table &lt;- league_table %&gt;% left_join(data_frame(club = teams, club_url = team_urls), by = &quot;club&quot;) %&gt;% as_data_frame() return(league_table) } B.3 Scrape domestic cups scrape_dom_cup &lt;- function(x) { cont &lt;- TRUE while(cont) { url_data &lt;- safe_read_html(x) if(is.null(url_data[[1]])) { closeAllConnections() Sys.sleep(5) } else { url_data &lt;- url_data[[1]] cont &lt;- FALSE } } teams &lt;- url_data %&gt;% html_nodes(&quot;#stats-fair-play a&quot;) %&gt;% html_text() %&gt;% as.character() %&gt;% trimws(which = &quot;both&quot;) team_urls &lt;- url_data %&gt;% html_nodes(&quot;#stats-fair-play a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% as.character() data_frame( club = teams, club_url = team_urls ) } B.4 Scrape games scrape_team &lt;- function(x, y) { x &lt;- gsub(&quot;/index&quot;, &quot;/fixtures&quot;, x, fixed = TRUE) cont &lt;- TRUE while(cont) { url_data &lt;- safe_read_html(x) if(is.null(url_data[[1]])) { closeAllConnections() Sys.sleep(5) } else { url_data &lt;- url_data[[1]] cont &lt;- FALSE } } date &lt;- url_data %&gt;% html_nodes(&quot;.headline&quot;) %&gt;% html_text() %&gt;% as.character() if (&quot;LIVE&quot; %in% date) { date[which(date == &quot;LIVE&quot;)] &lt;- format(Sys.Date(), &quot;%b %d, %Y&quot;) } date &lt;- mdy(date) home_team &lt;- url_data %&gt;% html_nodes(&quot;.score-home-team .team-name&quot;) %&gt;% html_text() %&gt;% as.character() away_team &lt;- url_data %&gt;% html_nodes(&quot;.score-away-team .team-name&quot;) %&gt;% html_text() %&gt;% as.character() home_score &lt;- url_data %&gt;% html_nodes(&quot;.home-score&quot;) %&gt;% html_text() %&gt;% as.character() %&gt;% gsub(&quot; &quot;, &quot;&quot;, x = .) %&gt;% gsub( &quot; *\\\\(.*?\\\\) *&quot;, &quot;&quot;, x = .) %&gt;% as.numeric() away_score &lt;- url_data %&gt;% html_nodes(&quot;.away-score&quot;) %&gt;% html_text() %&gt;% as.character() %&gt;% gsub(&quot; &quot;, &quot;&quot;, x = .) %&gt;% gsub( &quot; *\\\\(.*?\\\\) *&quot;, &quot;&quot;, x = .) %&gt;% as.numeric() competition &lt;- url_data %&gt;% html_nodes(&quot;.score-column.score-competition&quot;) %&gt;% html_text() %&gt;% as.character() team_data &lt;- data_frame( date = date, home = home_team, away = away_team, home_goals = home_score, away_goals = away_score, competition = competition ) %&gt;% arrange(date) %&gt;% unique() abbrev &lt;- as_data_frame(table(c(team_data$home, team_data$away))) %&gt;% top_n(n = 1, wt = n) %&gt;% select(Var1) %&gt;% flatten_chr() if (nrow(team_data) &lt; 3) { ret_data &lt;- data_frame( club = y, abbrev = y, team_data = NA ) } else { if (abbrev == &quot;Sporting&quot;) { team_data$home[which(team_data$home == &quot;Sporting&quot;)] &lt;- y team_data$away[which(team_data$away == &quot;Sporting&quot;)] &lt;- y ret_data &lt;- data_frame( club = y, abbrev = y, team_data = list(team_data) ) } else { team_data &lt;- filter(team_data, home != &quot;Sporting&quot;, away != &quot;Sporting&quot;) ret_data &lt;- data_frame( club = y, abbrev = abbrev, team_data = list(team_data) ) } } return(ret_data) } "],
["references.html", "References", " References "]
]
